{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7c59ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.tools import tool\n",
    "import getpass\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Gevin this is the user question \"{query}\" \\\n",
    "    and this the answer \"{answer}\"\\\n",
    "    Act as a virual assistant and repsond like human providing the answer for the user\n",
    "    \"\"\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return chain.run(query=\"what is 2 + 2\", answer=\"4\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def greating(query: str) -> str:\n",
    "    \"\"\"Welcome the user prompt by discriping the serivce that you provide.\n",
    "\n",
    "    Args:\n",
    "        query: the user prompt\n",
    "    \"\"\"\n",
    "    return \"This Sensorconnect framework\"\n",
    "\n",
    "\n",
    "tools = [add, multiply,greating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1a1a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2nph', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 1151, 'total_tokens': 1230, 'completion_time': 0.063500178, 'prompt_time': 0.17313925, 'queue_time': None, 'total_time': 0.23663942799999999}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e194062-787c-4233-89de-bccf4247a188-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'call_2nph', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1151, 'output_tokens': 79, 'total_tokens': 1230})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# query = \"Hello\"\n",
    "query=\"what is 2 + 2\"\n",
    "AIMessage=llm_with_tools.invoke(query)\n",
    "AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28702b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_tool: name='add' description='Adds a and b.' args_schema=<class 'pydantic.main.addSchema'> func=<function add at 0x000002B99FA7F4C0>\n"
     ]
    }
   ],
   "source": [
    "Ai_call=AIMessage.tool_calls\n",
    "for i in Ai_call:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply, \"greating\":greating}[i[\"name\"].lower()]\n",
    "    print(f\"selected_tool: {selected_tool}\")\n",
    "    tool_msg = selected_tool.invoke(i)\n",
    "    tool_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f47ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "messages = [HumanMessage(query)]\n",
    "messages.append(tool_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22e5c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
       " ToolMessage(content=\"You're wondering what 2 + 2 is? Well, let me think about that for a sec... Ah-ha! I've got it! The answer is... 4! That's right, when you add 2 and 2 together, you get 4!\", name='add', tool_call_id='call_2nph')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1882572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\n    Gevin this is the user query: what is 2 + 2     and this the answer 4\"    Act as a virual assistant and repsond like human providing the answer for the user\\n    '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_formatted_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196863d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

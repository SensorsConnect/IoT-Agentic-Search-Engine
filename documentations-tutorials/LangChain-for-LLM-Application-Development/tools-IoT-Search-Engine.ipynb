{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70733a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KnowledgeGraphTool\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.tools import tool\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Tutorial\"\n",
    "# Load a specific environment variable\n",
    "GKGraph_API_KEY = os.environ.get('GKGraph_API_KEY')\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486f91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: who is the current president of Egypt\n",
      "Name: President of Egypt\n",
      "Description: N/A\n",
      "Detailed Description: N/A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class KnowledgeGraphTool:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initializes the KnowledgeGraphTool with the provided API key.\n",
    "\n",
    "        Parameters:\n",
    "        api_key (str): The API key for accessing the Google Knowledge Graph API.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://kgsearch.googleapis.com/v1/entities:search\"\n",
    "\n",
    "    def search(self, query):\n",
    "        \"\"\"\n",
    "        Sends a search request to the Google Knowledge Graph API with the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The user's query to search for in the Knowledge Graph.\n",
    "\n",
    "        Returns:\n",
    "        dict: The JSON response from the API if the request is successful.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'query': query,\n",
    "            'key': self.api_key,\n",
    "            'limit': 1,\n",
    "            'indent': True\n",
    "        }\n",
    "        response = requests.get(self.base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            response.raise_for_status()\n",
    "\n",
    "    def extract_info(self, response):\n",
    "        \"\"\"\n",
    "        Extracts and returns the relevant information from the API response.\n",
    "\n",
    "        Parameters:\n",
    "        response (dict): The JSON response from the Knowledge Graph API.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary containing the name, description, and detailed description \n",
    "              from the response. Returns None if no relevant information is found.\n",
    "        \"\"\"\n",
    "        if 'itemListElement' in response and len(response['itemListElement']) > 0:\n",
    "            element = response['itemListElement'][0]['result']\n",
    "            name = element.get('name', 'N/A')\n",
    "            description = element.get('description', 'N/A')\n",
    "            detailed_description = element.get('detailedDescription', {}).get('articleBody', 'N/A')\n",
    "            return {\n",
    "                'name': name,\n",
    "                'description': description,\n",
    "                'detailed_description': detailed_description\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main function that handles user input, calls the search and extraction methods,\n",
    "    and prints the results.\n",
    "    \"\"\"\n",
    "    api_key = GKGraph_API_KEY\n",
    "    tool = KnowledgeGraphTool(api_key)\n",
    "    query = input(\"Enter your query: \")\n",
    "    response = tool.search(query)\n",
    "    info = tool.extract_info(response)\n",
    "    if info:\n",
    "        print(f\"Name: {info['name']}\")\n",
    "        print(f\"Description: {info['description']}\")\n",
    "        print(f\"Detailed Description: {info['detailed_description']}\")\n",
    "    else:\n",
    "        print(\"No information found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a09dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.tools import tool\n",
    "import getpass\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Gevin this is the user question \"{query}\" \\\n",
    "    and this the answer \"{answer}\"\\\n",
    "    Act as a virual assistant and repsond like human providing the answer for the user\n",
    "    \"\"\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "\n",
    "@tool\n",
    "def google_knowledge_graph(query: str) -> str:\n",
    "    \"\"\"This function call google knowledge graph API that provide answer \n",
    "    for some factual questions. The Knowledge Graph allows us to answer factual questions such as “How tall is the Eiffel Tower?”\n",
    "    or “Where were the 2016 Summer Olympics held.” \n",
    "    Our goal with the Knowledge Graph is for our systems to discover and surface publicly known, factual information when it’s determined to be useful.\n",
    "    Args:\n",
    "        query: the user prompt\n",
    "    \"\"\"\n",
    "    api_key = GKGraph_API_KEY\n",
    "    tool = KnowledgeGraphTool(api_key)\n",
    "#     query = input(\"Enter your query: \")\n",
    "    response = tool.search(query)\n",
    "    info = tool.extract_info(response)\n",
    "    if info:\n",
    "        print(f\"Name: {info['name']}\")\n",
    "        print(f\"Description: {info['description']}\")\n",
    "        print(f\"Detailed Description: {info['detailed_description']}\")\n",
    "        dictionary= {\n",
    "            \"name\": info['name'],\n",
    "            \"Description\":info['description'],\n",
    "            \"Detailed Description\" :info['detailed_description']\n",
    "        }\n",
    "        return  chain.run(query=query, answer=str(dictionary))\n",
    "    else: \n",
    "        print(\"No information found.\")\n",
    "        return chain.run(query=query, answer=\"No information found.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def greating(query: str) -> str:\n",
    "    \"\"\"Welcome the user prompt by discriping the serivce that you provide.\n",
    "\n",
    "    Args:\n",
    "        query: the user prompt\n",
    "    \"\"\"\n",
    "    return \"This Sensorconnect framework\"\n",
    "\n",
    "\n",
    "tools = [google_knowledge_graph,greating]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e79e34d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_h08j', 'function': {'arguments': '{\"query\":\"what is Tim Hortons\"}', 'name': 'google_knowledge_graph'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1112, 'total_tokens': 1184, 'completion_time': 0.057106974, 'prompt_time': 0.1702077, 'queue_time': None, 'total_time': 0.227314674}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ae00ce6c-f7fa-4657-b7f0-c6e4d38e73e6-0', tool_calls=[{'name': 'google_knowledge_graph', 'args': {'query': 'what is Tim Hortons'}, 'id': 'call_h08j', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1112, 'output_tokens': 72, 'total_tokens': 1184})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# query = \"Hello\"\n",
    "query=\"what's Tim Hortons\"\n",
    "AIMessage=llm_with_tools.invoke(query)\n",
    "AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "834d9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_tool: name='google_knowledge_graph' description='This function call google knowledge graph API that provide answer \\n    for some factual questions. The Knowledge Graph allows us to answer factual questions such as “How tall is the Eiffel Tower?”\\n    or “Where were the 2016 Summer Olympics held.” \\n    Our goal with the Knowledge Graph is for our systems to discover and surface publicly known, factual information when it’s determined to be useful.\\n    Args:\\n        query: the user prompt' args_schema=<class 'pydantic.main.google_knowledge_graphSchema'> func=<function google_knowledge_graph at 0x0000026A13371760>\n",
      "No information found.\n"
     ]
    }
   ],
   "source": [
    "Ai_call=AIMessage.tool_calls\n",
    "for i in Ai_call:\n",
    "    selected_tool = {\"google_knowledge_graph\": google_knowledge_graph, \"multiply\": multiply, \"greating\":greating}[i[\"name\"].lower()]\n",
    "    print(f\"selected_tool: {selected_tool}\")\n",
    "    tool_msg = selected_tool.invoke(i)\n",
    "    tool_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af1a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(query)]\n",
    "messages.append(tool_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55303a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"what's Tim Hortons\"),\n",
       " ToolMessage(content='I apologize for not having the information you were looking for initially!\\n\\nBut don\\'t worry, I\\'m here to help! Tim Hortons is actually a popular Canadian fast-food restaurant chain that was founded in 1964 by Tim Horton, a Canadian hockey player. The company is known for its coffee, donuts, and other baked goods, as well as its breakfast sandwiches and lunch items.\\n\\nIn fact, Tim Hortons is one of the largest fast-food chains in Canada, with over 4,000 locations worldwide. It\\'s often referred to as \"Tims\" by Canadians, and is a beloved part of Canadian culture.\\n\\nIf you\\'re not familiar with Tim Hortons, you might be surprised to learn that it\\'s a popular spot for a quick coffee and pastry or a hearty breakfast or lunch. They\\'re also known for their iconic \"Double-Double\" coffee, which is a classic combination of two creams and two sugars.\\n\\nI hope that helps! Do you have a favorite Tim Hortons item or memory?', name='google_knowledge_graph', tool_call_id='call_h08j')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f271a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

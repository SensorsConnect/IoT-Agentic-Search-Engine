{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd566d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.7 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/43.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.7/43.7 kB 428.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: Pillow in c:\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: sympy in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/21/4f/5ee44681c7ea827f9d3c104ca429865b41c05a4163eff7f0599152c2e682/safetensors-0.4.4-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.4-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting fsspec (from torch>=1.11.0->sentence-transformers)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/5e/44/73bea497ac69bafde2ee4269292fa3b41f1198f4bb7bbaaabde30ad29d4a/fsspec-2024.6.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 227.1/227.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/9.5 MB 12.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.0/9.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/9.5 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.7/9.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.7/9.5 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.7/9.5 MB 15.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.5/9.5 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.7/9.5 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.2/9.5 MB 14.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.7/9.5 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.5 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.5 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 389.1/417.5 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 417.5/417.5 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 177.6/177.6 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.4-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.0/286.0 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.2\n",
      "    Uninstalling safetensors-0.3.2:\n",
      "      Successfully uninstalled safetensors-0.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "Successfully installed fsspec-2024.6.1 huggingface-hub-0.24.6 safetensors-0.4.4 sentence-transformers-3.0.1 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.6.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49826627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02250258 -0.07829181 -0.02303076 ... -0.00827928  0.02652692\n",
      "  -0.00201897]\n",
      " [ 0.04170238  0.0010974  -0.01553418 ... -0.02181626 -0.0635936\n",
      "  -0.00875283]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3651c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b841435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb72b4b19a4ddda4b36faaae486602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Abdelrahman Elewah\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f848c3686dc64ea592b00ffc0e90bea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c740e06acb045b5b582b9f01fca9d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7440ffd0f3b24c8e834c45ad1af813d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5debb4c88c92410d94016924e1865ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3badc2d57f54aa8ba834bedafa9a60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0225, -0.0783, -0.0230,  ..., -0.0083,  0.0265, -0.0020],\n",
      "        [ 0.0417,  0.0011, -0.0155,  ..., -0.0218, -0.0636, -0.0088],\n",
      "        [ 0.0416, -0.0073, -0.0287,  ..., -0.0012,  0.0058,  0.0316]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted', 'sentence is example that each word takes id']\n",
    "# sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9807366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a702320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "for i in encoded_input:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4fbbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9685f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 2027, 2007, 2023, 2746, 6255,    2,    1,    1,    1],\n",
       "        [   0, 2173, 6255, 2007, 4995,    2,    1,    1,    1,    1],\n",
       "        [   0, 6255, 2007, 2746, 2012, 2173, 2777, 3142, 8913,    2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b8c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9834f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docarray import BaseDoc\n",
    "from docarray.typing import NdArray\n",
    "\n",
    "class ToyDoc(BaseDoc):\n",
    "    text: str = ''\n",
    "    embedding: NdArray[128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62dbe47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - docarray - Index file does not exist: G:\\My Drive\\ontario tech era\\python-repo\\SensorsConnect\\langChain-Course\\documentations-tutorials\\VectorDB\\workspace_path\\InMemoryExactNNIndexer[ToyDoc][ToyDocWithMatchesAndScores]/index.bin. Initializing empty InMemoryExactNNIndex.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mToyDoc\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mid\u001b[0m=\u001b[32m'cf878d4f70d130f722117b95c9514f31'\u001b[0m,\n",
      "    \u001b[33mtext\u001b[0m=\u001b[32m'toy doc 596'\u001b[0m,\n",
      "    \u001b[33membedding\u001b[0m=\u001b[1;35mNdArray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.36303533\u001b[0m, \u001b[1;36m0.10351704\u001b[0m, \u001b[1;36m0.6127303\u001b[0m , \u001b[1;36m0.88562399\u001b[0m, \u001b[1;36m0.45163972\u001b[0m,\n",
      "         \u001b[1;36m0.52189729\u001b[0m, \u001b[1;36m0.44147967\u001b[0m, \u001b[1;36m0.95455978\u001b[0m, \u001b[1;36m0.84453813\u001b[0m, \u001b[1;36m0.48048236\u001b[0m,\n",
      "         \u001b[1;36m0.2122873\u001b[0m , \u001b[1;36m0.8658788\u001b[0m , \u001b[1;36m0.20969576\u001b[0m, \u001b[1;36m0.94723943\u001b[0m, \u001b[1;36m0.34405264\u001b[0m,\n",
      "         \u001b[1;36m0.31180417\u001b[0m, \u001b[1;36m0.12566114\u001b[0m, \u001b[1;36m0.29034632\u001b[0m, \u001b[1;36m0.34571828\u001b[0m, \u001b[1;36m0.71184984\u001b[0m,\n",
      "         \u001b[1;36m0.11974517\u001b[0m, \u001b[1;36m0.94427399\u001b[0m, \u001b[1;36m0.12388932\u001b[0m, \u001b[1;36m0.92973246\u001b[0m, \u001b[1;36m0.71154235\u001b[0m,\n",
      "         \u001b[1;36m0.71410255\u001b[0m, \u001b[1;36m0.01816357\u001b[0m, \u001b[1;36m0.81373274\u001b[0m, \u001b[1;36m0.39355815\u001b[0m, \u001b[1;36m0.32184818\u001b[0m,\n",
      "         \u001b[1;36m0.38007508\u001b[0m, \u001b[1;36m0.46647514\u001b[0m, \u001b[1;36m0.79461604\u001b[0m, \u001b[1;36m0.84307049\u001b[0m, \u001b[1;36m0.43097007\u001b[0m,\n",
      "         \u001b[1;36m0.4198746\u001b[0m , \u001b[1;36m0.02910279\u001b[0m, \u001b[1;36m0.99744866\u001b[0m, \u001b[1;36m0.50146726\u001b[0m, \u001b[1;36m0.80918319\u001b[0m,\n",
      "         \u001b[1;36m0.94658632\u001b[0m, \u001b[1;36m0.49910158\u001b[0m, \u001b[1;36m0.79140675\u001b[0m, \u001b[1;36m0.95051794\u001b[0m, \u001b[1;36m0.33912101\u001b[0m,\n",
      "         \u001b[1;36m0.69168492\u001b[0m, \u001b[1;36m0.59947871\u001b[0m, \u001b[1;36m0.38238263\u001b[0m, \u001b[1;36m0.76517805\u001b[0m, \u001b[1;36m0.38602666\u001b[0m,\n",
      "         \u001b[1;36m0.59903189\u001b[0m, \u001b[1;36m0.94523261\u001b[0m, \u001b[1;36m0.41767843\u001b[0m, \u001b[1;36m0.36770561\u001b[0m, \u001b[1;36m0.7817798\u001b[0m ,\n",
      "         \u001b[1;36m0.42114472\u001b[0m, \u001b[1;36m0.37204277\u001b[0m, \u001b[1;36m0.51144458\u001b[0m, \u001b[1;36m0.42528325\u001b[0m, \u001b[1;36m0.44713802\u001b[0m,\n",
      "         \u001b[1;36m0.22857368\u001b[0m, \u001b[1;36m0.03030275\u001b[0m, \u001b[1;36m0.60664197\u001b[0m, \u001b[1;36m0.0115612\u001b[0m , \u001b[1;36m0.79386439\u001b[0m,\n",
      "         \u001b[1;36m0.86117917\u001b[0m, \u001b[1;36m0.38253573\u001b[0m, \u001b[1;36m0.82872346\u001b[0m, \u001b[1;36m0.71772002\u001b[0m, \u001b[1;36m0.1978277\u001b[0m ,\n",
      "         \u001b[1;36m0.26943787\u001b[0m, \u001b[1;36m0.9722013\u001b[0m , \u001b[1;36m0.88039099\u001b[0m, \u001b[1;36m0.424516\u001b[0m  , \u001b[1;36m0.4261708\u001b[0m ,\n",
      "         \u001b[1;36m0.84176253\u001b[0m, \u001b[1;36m0.68647068\u001b[0m, \u001b[1;36m0.91843761\u001b[0m, \u001b[1;36m0.92184718\u001b[0m, \u001b[1;36m0.8048322\u001b[0m ,\n",
      "         \u001b[1;36m0.50506674\u001b[0m, \u001b[1;36m0.04552188\u001b[0m, \u001b[1;36m0.74737045\u001b[0m, \u001b[1;36m0.41308814\u001b[0m, \u001b[1;36m0.82295525\u001b[0m,\n",
      "         \u001b[1;36m0.66641426\u001b[0m, \u001b[1;36m0.62339031\u001b[0m, \u001b[1;36m0.46208438\u001b[0m, \u001b[1;36m0.35067863\u001b[0m, \u001b[1;36m0.20469429\u001b[0m,\n",
      "         \u001b[1;36m0.71247161\u001b[0m, \u001b[1;36m0.78665776\u001b[0m, \u001b[1;36m0.62417149\u001b[0m, \u001b[1;36m0.86199572\u001b[0m, \u001b[1;36m0.38069162\u001b[0m,\n",
      "         \u001b[1;36m0.02202453\u001b[0m, \u001b[1;36m0.66838087\u001b[0m, \u001b[1;36m0.57002219\u001b[0m, \u001b[1;36m0.21122299\u001b[0m, \u001b[1;36m0.31874114\u001b[0m,\n",
      "         \u001b[1;36m0.36004125\u001b[0m, \u001b[1;36m0.70064181\u001b[0m, \u001b[1;36m0.39578466\u001b[0m, \u001b[1;36m0.58380511\u001b[0m, \u001b[1;36m0.68042618\u001b[0m,\n",
      "         \u001b[1;36m0.26504475\u001b[0m, \u001b[1;36m0.1862022\u001b[0m , \u001b[1;36m0.11806894\u001b[0m, \u001b[1;36m0.26669338\u001b[0m, \u001b[1;36m0.2950332\u001b[0m ,\n",
      "         \u001b[1;36m0.68217158\u001b[0m, \u001b[1;36m0.46093687\u001b[0m, \u001b[1;36m0.5117087\u001b[0m , \u001b[1;36m0.73373501\u001b[0m, \u001b[1;36m0.02475212\u001b[0m,\n",
      "         \u001b[1;36m0.77829108\u001b[0m, \u001b[1;36m0.11156908\u001b[0m, \u001b[1;36m0.93615598\u001b[0m, \u001b[1;36m0.83046789\u001b[0m, \u001b[1;36m0.86024812\u001b[0m,\n",
      "         \u001b[1;36m0.41119359\u001b[0m, \u001b[1;36m0.14934089\u001b[0m, \u001b[1;36m0.12957052\u001b[0m, \u001b[1;36m0.89426034\u001b[0m, \u001b[1;36m0.05598963\u001b[0m,\n",
      "         \u001b[1;36m0.3461007\u001b[0m , \u001b[1;36m0.59802112\u001b[0m, \u001b[1;36m0.76247209\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mToyDoc\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mid\u001b[0m=\u001b[32m'7385e71f421472ffb74d329be285c647'\u001b[0m,\n",
      "    \u001b[33mtext\u001b[0m=\u001b[32m'toy doc 78'\u001b[0m,\n",
      "    \u001b[33membedding\u001b[0m=\u001b[1;35mNdArray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.36694325\u001b[0m, \u001b[1;36m0.93628475\u001b[0m, \u001b[1;36m0.37912976\u001b[0m, \u001b[1;36m0.54062732\u001b[0m, \u001b[1;36m0.24778555\u001b[0m,\n",
      "         \u001b[1;36m0.44212224\u001b[0m, \u001b[1;36m0.81100654\u001b[0m, \u001b[1;36m0.71777236\u001b[0m, \u001b[1;36m0.99613619\u001b[0m, \u001b[1;36m0.1600981\u001b[0m ,\n",
      "         \u001b[1;36m0.06610302\u001b[0m, \u001b[1;36m0.923664\u001b[0m  , \u001b[1;36m0.17138439\u001b[0m, \u001b[1;36m0.49892291\u001b[0m, \u001b[1;36m0.56573618\u001b[0m,\n",
      "         \u001b[1;36m0.52578658\u001b[0m, \u001b[1;36m0.76336119\u001b[0m, \u001b[1;36m0.0814125\u001b[0m , \u001b[1;36m0.18921653\u001b[0m, \u001b[1;36m0.81872084\u001b[0m,\n",
      "         \u001b[1;36m0.09059606\u001b[0m, \u001b[1;36m0.14969811\u001b[0m, \u001b[1;36m0.59854249\u001b[0m, \u001b[1;36m0.86045097\u001b[0m, \u001b[1;36m0.73616459\u001b[0m,\n",
      "         \u001b[1;36m0.0955524\u001b[0m , \u001b[1;36m0.44401599\u001b[0m, \u001b[1;36m0.52847905\u001b[0m, \u001b[1;36m0.3978549\u001b[0m , \u001b[1;36m0.9500598\u001b[0m ,\n",
      "         \u001b[1;36m0.77217496\u001b[0m, \u001b[1;36m0.31821644\u001b[0m, \u001b[1;36m0.74795639\u001b[0m, \u001b[1;36m0.79358018\u001b[0m, \u001b[1;36m0.51136635\u001b[0m,\n",
      "         \u001b[1;36m0.56204903\u001b[0m, \u001b[1;36m0.75564182\u001b[0m, \u001b[1;36m0.23021474\u001b[0m, \u001b[1;36m0.92213383\u001b[0m, \u001b[1;36m0.55380821\u001b[0m,\n",
      "         \u001b[1;36m0.81717688\u001b[0m, \u001b[1;36m0.52638513\u001b[0m, \u001b[1;36m0.62093478\u001b[0m, \u001b[1;36m0.58350444\u001b[0m, \u001b[1;36m0.36245817\u001b[0m,\n",
      "         \u001b[1;36m0.27040902\u001b[0m, \u001b[1;36m0.68051034\u001b[0m, \u001b[1;36m0.11059093\u001b[0m, \u001b[1;36m0.03827634\u001b[0m, \u001b[1;36m0.02175307\u001b[0m,\n",
      "         \u001b[1;36m0.57172196\u001b[0m, \u001b[1;36m0.80015008\u001b[0m, \u001b[1;36m0.18433066\u001b[0m, \u001b[1;36m0.89478791\u001b[0m, \u001b[1;36m0.32205157\u001b[0m,\n",
      "         \u001b[1;36m0.49539747\u001b[0m, \u001b[1;36m0.98760441\u001b[0m, \u001b[1;36m0.91509415\u001b[0m, \u001b[1;36m0.8435242\u001b[0m , \u001b[1;36m0.30397629\u001b[0m,\n",
      "         \u001b[1;36m0.15268248\u001b[0m, \u001b[1;36m0.68262153\u001b[0m, \u001b[1;36m0.0731192\u001b[0m , \u001b[1;36m0.60404524\u001b[0m, \u001b[1;36m0.21414682\u001b[0m,\n",
      "         \u001b[1;36m0.96839039\u001b[0m, \u001b[1;36m0.03546038\u001b[0m, \u001b[1;36m0.50757192\u001b[0m, \u001b[1;36m0.39171302\u001b[0m, \u001b[1;36m0.72011767\u001b[0m,\n",
      "         \u001b[1;36m0.62006148\u001b[0m, \u001b[1;36m0.98029561\u001b[0m, \u001b[1;36m0.44205302\u001b[0m, \u001b[1;36m0.64371587\u001b[0m, \u001b[1;36m0.80379461\u001b[0m,\n",
      "         \u001b[1;36m0.7522901\u001b[0m , \u001b[1;36m0.81919789\u001b[0m, \u001b[1;36m0.87275431\u001b[0m, \u001b[1;36m0.76370444\u001b[0m, \u001b[1;36m0.89987623\u001b[0m,\n",
      "         \u001b[1;36m0.36288183\u001b[0m, \u001b[1;36m0.36259318\u001b[0m, \u001b[1;36m0.95845267\u001b[0m, \u001b[1;36m0.19674794\u001b[0m, \u001b[1;36m0.75694858\u001b[0m,\n",
      "         \u001b[1;36m0.42800752\u001b[0m, \u001b[1;36m0.54493985\u001b[0m, \u001b[1;36m0.3170258\u001b[0m , \u001b[1;36m0.58343175\u001b[0m, \u001b[1;36m0.68766438\u001b[0m,\n",
      "         \u001b[1;36m0.18928614\u001b[0m, \u001b[1;36m0.81682133\u001b[0m, \u001b[1;36m0.73288914\u001b[0m, \u001b[1;36m0.49363893\u001b[0m, \u001b[1;36m0.34247007\u001b[0m,\n",
      "         \u001b[1;36m0.67242292\u001b[0m, \u001b[1;36m0.92126705\u001b[0m, \u001b[1;36m0.61291835\u001b[0m, \u001b[1;36m0.13384342\u001b[0m, \u001b[1;36m0.9733618\u001b[0m ,\n",
      "         \u001b[1;36m0.54520031\u001b[0m, \u001b[1;36m0.24535423\u001b[0m, \u001b[1;36m0.41236484\u001b[0m, \u001b[1;36m0.89950067\u001b[0m, \u001b[1;36m0.23853031\u001b[0m,\n",
      "         \u001b[1;36m0.52794849\u001b[0m, \u001b[1;36m0.52760882\u001b[0m, \u001b[1;36m0.54811126\u001b[0m, \u001b[1;36m0.20045402\u001b[0m, \u001b[1;36m0.1138807\u001b[0m ,\n",
      "         \u001b[1;36m0.78120258\u001b[0m, \u001b[1;36m0.44454859\u001b[0m, \u001b[1;36m0.44891866\u001b[0m, \u001b[1;36m0.93539849\u001b[0m, \u001b[1;36m0.23817545\u001b[0m,\n",
      "         \u001b[1;36m0.45591463\u001b[0m, \u001b[1;36m0.56178043\u001b[0m, \u001b[1;36m0.6429282\u001b[0m , \u001b[1;36m0.9734849\u001b[0m , \u001b[1;36m0.73781099\u001b[0m,\n",
      "         \u001b[1;36m0.95398043\u001b[0m, \u001b[1;36m0.91110861\u001b[0m, \u001b[1;36m0.32774179\u001b[0m, \u001b[1;36m0.02667196\u001b[0m, \u001b[1;36m0.17964884\u001b[0m,\n",
      "         \u001b[1;36m0.56248585\u001b[0m, \u001b[1;36m0.18528101\u001b[0m, \u001b[1;36m0.68840721\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from docarray import DocList\n",
    "import numpy as np\n",
    "from vectordb import InMemoryExactNNVectorDB, HNSWVectorDB\n",
    "\n",
    "# Specify your workspace path\n",
    "db = InMemoryExactNNVectorDB[ToyDoc](workspace='./workspace_path')\n",
    "\n",
    "# Index a list of documents with random embeddings\n",
    "doc_list = [ToyDoc(text=f'toy doc {i}', embedding=np.random.rand(128)) for i in range(1000)]\n",
    "db.index(inputs=DocList[ToyDoc](doc_list))\n",
    "\n",
    "# Perform a search query\n",
    "query = ToyDoc(text='50', embedding=np.random.rand(128))\n",
    "results = db.search(inputs=DocList[ToyDoc]([query]), limit=2)\n",
    "\n",
    "print(query.text)\n",
    "# Print out the matches\n",
    "for m in results[0].matches:\n",
    "    print(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2373fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0225, -0.0783, -0.0230,  ..., -0.0083,  0.0265, -0.0020],\n",
       "        [ 0.0417,  0.0011, -0.0155,  ..., -0.0218, -0.0636, -0.0088],\n",
       "        [ 0.0416, -0.0073, -0.0287,  ..., -0.0012,  0.0058,  0.0316]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2483f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.2503e-02, -7.8292e-02, -2.3031e-02, -5.1000e-03, -8.0340e-02,\n",
      "         3.9132e-02,  1.1343e-02,  3.4648e-03, -2.9457e-02, -1.8893e-02,\n",
      "         9.4743e-02,  2.9275e-02,  3.9486e-02, -4.6317e-02,  2.5425e-02,\n",
      "        -3.2200e-02,  6.2193e-02,  1.5559e-02, -4.6780e-02,  5.0390e-02,\n",
      "         1.4611e-02,  2.3141e-02,  1.2207e-02,  2.5070e-02,  2.9365e-03,\n",
      "        -4.1982e-02, -4.0103e-03, -2.2784e-02, -7.6860e-03, -3.3109e-02,\n",
      "         3.2212e-02, -2.0999e-02,  1.1673e-02, -9.8507e-02,  1.7793e-06,\n",
      "        -2.2993e-02, -1.3114e-02, -2.8022e-02, -6.9997e-02,  2.5931e-02,\n",
      "        -2.8950e-02,  8.7634e-02, -1.2092e-02,  3.9861e-02, -3.3138e-02,\n",
      "         3.5911e-02,  3.4610e-02,  6.4978e-02, -3.0082e-02,  6.9819e-02,\n",
      "        -3.9952e-03, -1.0160e-03, -3.5018e-02, -4.3657e-02,  5.0803e-02,\n",
      "         4.6876e-02,  5.3966e-02, -4.0301e-02,  3.2014e-03,  1.3662e-02,\n",
      "         3.8219e-02, -3.2384e-03, -7.8460e-04, -1.7119e-02,  6.9044e-03,\n",
      "        -1.0924e-02,  8.6331e-03, -1.8236e-02,  1.8793e-02,  1.5499e-02,\n",
      "         1.0215e-02, -2.4838e-03,  1.0315e-02,  6.2489e-02,  3.6032e-03,\n",
      "        -6.2663e-03, -2.0341e-02, -6.7234e-03, -3.5477e-02,  3.4354e-02,\n",
      "         6.7228e-02,  9.0687e-02,  1.3244e-02,  2.0659e-02, -2.7869e-02,\n",
      "         4.2969e-02, -4.6686e-02,  1.5012e-02, -6.6228e-02, -2.2759e-02,\n",
      "        -6.2499e-02, -2.5845e-02,  7.3130e-04,  1.1465e-02,  5.6638e-02,\n",
      "         2.0624e-03, -4.0925e-02, -4.5505e-02,  1.6696e-02, -8.3156e-02,\n",
      "         2.0907e-03, -8.7092e-03,  1.0769e-04,  3.3744e-02,  5.6035e-03,\n",
      "        -1.6698e-02,  4.4791e-02,  6.3181e-03, -6.4590e-02,  5.2910e-02,\n",
      "         1.9302e-02, -6.2015e-03, -1.1876e-01,  3.5596e-02, -2.2886e-02,\n",
      "        -1.5187e-02, -5.9266e-03, -1.5718e-04,  1.0707e-02,  3.8608e-03,\n",
      "        -6.8701e-02, -1.6975e-02, -2.7973e-02,  2.8048e-02,  2.4779e-02,\n",
      "         1.2028e-02, -6.8639e-02,  4.9277e-02,  1.8758e-02, -2.4234e-02,\n",
      "        -2.0529e-02, -1.0793e-02,  2.4649e-02, -3.3332e-02, -3.2840e-02,\n",
      "         2.9198e-02,  4.9203e-02, -7.1336e-03, -1.6339e-02,  1.7859e-03,\n",
      "         2.1807e-02, -8.9023e-02, -3.3705e-02,  5.7722e-03, -4.5657e-02,\n",
      "         3.3989e-02,  3.5278e-02, -3.1263e-02,  8.1083e-03,  2.6861e-02,\n",
      "        -2.2390e-03,  2.8127e-02, -1.7538e-02, -1.4459e-02, -3.3348e-02,\n",
      "        -1.6296e-02,  9.7004e-02, -8.1107e-03, -2.4667e-02, -5.8746e-02,\n",
      "         8.7490e-04,  1.6724e-02,  9.1538e-03, -1.1799e-03, -2.9302e-03,\n",
      "         4.2246e-03, -2.1653e-02,  4.2931e-02, -5.8610e-02,  3.1342e-02,\n",
      "        -1.2952e-03, -1.1130e-02, -2.8202e-02,  8.7732e-02,  2.0688e-02,\n",
      "         1.4140e-02,  1.3823e-02, -1.9418e-02, -9.0104e-02, -3.8147e-03,\n",
      "        -2.9115e-03,  3.0975e-02, -1.1877e-02,  1.8829e-02, -4.5907e-02,\n",
      "         4.9821e-02, -8.3918e-03, -4.2971e-02, -3.2360e-02, -3.8380e-02,\n",
      "        -2.9975e-02,  3.6988e-02, -4.4459e-03, -1.9478e-02, -2.7153e-02,\n",
      "         2.4325e-02,  9.1638e-04,  5.8500e-02,  1.9271e-02, -2.5729e-02,\n",
      "         4.0868e-02,  4.3686e-03,  5.1352e-02,  1.5708e-02, -2.4633e-02,\n",
      "        -9.7961e-03,  2.0612e-03, -4.6664e-02,  3.1959e-02, -3.7343e-02,\n",
      "         9.3515e-02,  1.8542e-02, -2.6022e-02,  8.0577e-03, -6.3858e-05,\n",
      "        -4.7415e-03,  2.1736e-02, -4.0362e-02, -3.9723e-02,  6.6051e-02,\n",
      "        -3.2019e-02, -1.5236e-02, -1.5310e-02,  5.5815e-03,  3.9678e-02,\n",
      "        -5.9888e-02, -2.9491e-02, -1.5348e-02, -3.3298e-02, -1.3586e-02,\n",
      "        -2.2370e-02,  1.8113e-03, -2.5352e-04,  7.3093e-03, -4.9633e-02,\n",
      "         3.7463e-02, -4.4249e-02, -8.7788e-02, -1.9553e-02, -7.4462e-02,\n",
      "        -5.2837e-03, -8.5995e-03,  1.6566e-02,  1.9918e-02, -9.9419e-03,\n",
      "        -2.8521e-03,  7.2145e-02, -1.9903e-02,  2.9514e-02, -5.9720e-02,\n",
      "         5.0088e-02, -2.5491e-02,  2.3392e-02, -7.1268e-03,  7.3868e-03,\n",
      "        -7.1794e-02,  9.1506e-04,  2.1987e-02,  4.1591e-03,  1.7954e-02,\n",
      "         6.3221e-02, -2.4794e-03, -5.2658e-03,  2.3497e-02, -2.6196e-02,\n",
      "        -3.7123e-02,  2.1568e-02, -5.8536e-02, -1.7958e-02, -1.2001e-02,\n",
      "         8.9648e-04, -1.4769e-02,  4.9694e-02,  6.9796e-03,  2.6437e-02,\n",
      "         4.6177e-02,  3.2043e-02, -3.6601e-02, -5.0843e-03,  6.8867e-02,\n",
      "         5.6800e-02, -1.4678e-02, -4.7847e-02,  1.2187e-02, -2.5042e-02,\n",
      "         3.1244e-02, -1.7944e-02, -3.0583e-02,  1.7171e-03,  7.0213e-02,\n",
      "         5.6738e-02, -1.7937e-02,  2.4400e-02, -2.8653e-02, -1.1587e-02,\n",
      "        -2.7041e-02,  3.9513e-02,  4.2996e-02,  2.9097e-02,  2.8084e-02,\n",
      "        -4.6275e-02, -4.2829e-03,  1.1990e-02, -1.2023e-02, -9.4694e-03,\n",
      "         2.3507e-02, -3.0063e-02, -1.6961e-02, -1.5973e-03, -1.3061e-02,\n",
      "         5.3588e-02,  2.5378e-02,  2.6025e-02,  6.2741e-02, -2.2646e-02,\n",
      "         6.5867e-03, -3.4878e-02, -8.8899e-03, -3.3227e-02, -1.8160e-02,\n",
      "        -6.4545e-03,  1.0202e-02, -1.2516e-02,  4.2016e-02,  1.1215e-02,\n",
      "        -2.1335e-02,  1.0562e-02,  1.9982e-02,  1.8380e-02,  3.2969e-03,\n",
      "        -8.7044e-03,  1.9076e-02, -4.4101e-02,  9.5772e-02,  2.7362e-02,\n",
      "         1.7653e-02, -2.2042e-02,  3.7063e-02, -6.5267e-04, -1.4451e-02,\n",
      "         1.0979e-02, -8.4049e-03, -3.2620e-03, -2.2072e-02, -1.9035e-02,\n",
      "        -1.6056e-02, -4.0815e-02,  1.1161e-02, -6.0242e-02, -6.9668e-02,\n",
      "        -1.7330e-02,  2.8794e-02, -6.7962e-02, -3.1376e-02, -5.5136e-02,\n",
      "        -2.0358e-02,  2.8901e-02,  1.3779e-02,  6.8051e-03, -2.4322e-03,\n",
      "         7.2153e-02, -1.1746e-03, -3.5721e-02,  3.5479e-02, -1.9638e-03,\n",
      "        -7.7664e-03,  3.0194e-02,  1.8542e-02, -5.3999e-02,  3.3243e-02,\n",
      "         5.7303e-03,  1.3399e-02,  4.5161e-03,  4.8892e-02, -3.1435e-02,\n",
      "         3.6217e-02,  3.6545e-02, -4.7921e-02, -1.4488e-02,  4.9313e-02,\n",
      "         2.8698e-02, -5.5146e-02,  2.7474e-02,  1.2780e-02, -7.0463e-02,\n",
      "         7.6906e-03, -5.2469e-03, -5.3392e-02, -1.7081e-02,  4.7768e-02,\n",
      "         2.3806e-02, -4.0980e-02, -1.2741e-02,  4.6634e-02,  5.0348e-03,\n",
      "         6.6055e-03,  2.9057e-02,  4.1597e-02, -3.8213e-02, -1.1439e-02,\n",
      "         1.7164e-02,  5.7087e-03,  1.0729e-02, -1.8059e-02, -5.0638e-02,\n",
      "         4.5492e-02,  1.4074e-02,  4.2558e-02, -3.2235e-02,  4.1767e-02,\n",
      "         1.1499e-02,  3.9240e-03,  2.0446e-02,  1.5255e-02,  3.8040e-02,\n",
      "         2.5458e-02, -4.6927e-03,  1.8322e-02,  2.7602e-02, -2.8916e-02,\n",
      "        -4.9898e-02, -1.6194e-02,  9.8702e-02, -4.2636e-02, -1.8848e-02,\n",
      "        -1.0701e-02, -3.2141e-02,  4.1532e-02, -2.3870e-02,  8.3993e-03,\n",
      "        -1.0090e-03, -3.1134e-02, -3.8649e-02, -3.0674e-02, -3.8890e-02,\n",
      "        -3.6562e-02,  3.2942e-03,  2.0094e-02,  2.3073e-02, -4.7747e-02,\n",
      "         8.5598e-03,  2.2194e-02,  1.4923e-01, -1.9177e-02,  1.4348e-02,\n",
      "         4.3995e-02, -2.2776e-03,  1.3811e-03,  3.2316e-02,  6.5753e-02,\n",
      "         2.2700e-02,  2.1810e-02, -3.0069e-02,  1.5419e-02,  6.9595e-02,\n",
      "        -3.8842e-02, -1.0926e-01, -7.5107e-03,  1.1960e-02,  1.2755e-02,\n",
      "         1.8959e-02,  4.5423e-02, -4.6091e-02, -5.1717e-03, -1.1753e-02,\n",
      "        -8.6766e-03, -2.0886e-02,  4.4937e-02,  1.5543e-02,  1.3286e-02,\n",
      "        -3.6746e-02,  1.4087e-02,  2.7777e-03,  2.7787e-03,  2.9919e-02,\n",
      "        -3.0135e-02, -4.6399e-02, -5.6087e-02, -7.9464e-03,  3.5832e-02,\n",
      "        -2.3763e-02,  3.0456e-02,  4.3817e-03, -1.4913e-02, -2.0019e-02,\n",
      "         4.8452e-03, -1.4073e-03, -3.5315e-02,  5.5882e-03,  7.4555e-03,\n",
      "         1.5149e-03,  4.0353e-02, -6.4500e-03, -2.2650e-03, -3.9120e-02,\n",
      "         1.0510e-02,  1.1445e-02,  2.8517e-02,  2.4323e-02, -8.1661e-02,\n",
      "        -4.0611e-02,  4.4872e-02,  5.7610e-04,  3.6637e-02, -5.0790e-02,\n",
      "         3.4264e-02,  2.4984e-02,  1.1740e-02,  1.7150e-02,  2.1281e-02,\n",
      "        -1.8307e-02, -5.0870e-02, -1.7920e-02,  2.4500e-02, -8.8423e-03,\n",
      "         1.7027e-02, -2.6982e-03, -7.8631e-02,  5.8888e-02,  2.7941e-03,\n",
      "         1.1867e-02, -3.2949e-02,  2.4992e-02, -3.3903e-02, -7.4675e-02,\n",
      "         2.8546e-03, -4.5951e-03,  1.3656e-03, -6.9154e-02,  3.5496e-03,\n",
      "        -1.4017e-02,  6.5401e-03, -5.4974e-02,  4.2833e-02, -5.3359e-02,\n",
      "         3.1816e-03,  1.0433e-01,  3.4274e-02,  4.0734e-02,  1.8962e-02,\n",
      "         2.4427e-02, -1.2966e-02,  6.0020e-02,  3.9283e-02,  7.5803e-02,\n",
      "        -1.5184e-02, -7.9833e-03,  3.4759e-02, -1.8661e-02, -6.9607e-02,\n",
      "        -7.1310e-02,  2.7724e-02, -3.2037e-02,  3.1005e-02,  1.2668e-03,\n",
      "        -6.6939e-33, -3.9147e-02, -3.4621e-02,  2.0693e-03,  6.2110e-02,\n",
      "        -4.1661e-02, -9.9015e-03, -1.6743e-02,  7.9450e-03, -1.0779e-03,\n",
      "         2.8501e-02, -3.1968e-02,  1.7913e-03,  3.1365e-02, -1.4070e-02,\n",
      "         1.9363e-02,  7.5116e-03,  3.5290e-02, -1.1661e-02, -2.8055e-03,\n",
      "        -1.1996e-02, -2.9714e-02, -1.7658e-02,  4.5253e-02, -1.3879e-03,\n",
      "        -7.8715e-03, -8.1742e-03, -5.4776e-02, -1.1204e-02, -6.2667e-02,\n",
      "        -2.1554e-02,  5.1628e-03, -2.6067e-02, -1.9769e-02, -2.4116e-02,\n",
      "        -3.3997e-02,  4.5598e-02, -5.3801e-03, -5.1583e-02,  2.7813e-02,\n",
      "         3.8653e-02, -9.1719e-02, -5.4330e-02, -2.3813e-02,  8.4734e-03,\n",
      "        -2.5615e-02, -1.9426e-02, -5.7907e-03, -3.5358e-02,  3.6812e-02,\n",
      "        -4.7591e-02, -3.9351e-02,  1.0364e-03, -3.5692e-02,  4.0590e-02,\n",
      "        -3.4165e-03,  2.3570e-02, -1.6553e-02, -1.5157e-03, -4.2270e-02,\n",
      "         1.8589e-02,  4.5194e-02,  5.0086e-02, -3.6245e-02, -3.3802e-02,\n",
      "        -2.1523e-02,  7.7486e-03,  3.4793e-03,  8.4224e-04,  1.1884e-02,\n",
      "         6.9764e-02,  8.0296e-03,  1.0467e-01, -4.3428e-02,  1.0993e-01,\n",
      "         2.2769e-02, -3.1418e-02, -1.1490e-02, -3.5534e-03,  2.8218e-02,\n",
      "        -1.6215e-02,  6.3287e-02,  1.1281e-02, -4.5399e-02, -4.2389e-02,\n",
      "        -4.7706e-02, -4.9346e-02, -3.7288e-03,  3.3871e-02, -3.0911e-02,\n",
      "         2.0678e-02,  3.0863e-02,  6.2914e-02,  1.7047e-02, -1.7212e-02,\n",
      "        -3.7712e-02,  3.4521e-02, -4.0961e-02,  4.8886e-03, -3.0061e-02,\n",
      "        -8.4137e-03, -4.0995e-02, -3.9802e-02, -5.3927e-02,  1.6564e-02,\n",
      "         5.9687e-02,  3.6152e-02,  4.9893e-02,  1.4500e-02, -1.0917e-01,\n",
      "        -1.4375e-02, -1.3637e-02,  1.6253e-02, -1.1708e-03, -3.0968e-02,\n",
      "        -2.9001e-02, -6.6636e-03,  9.0412e-03,  4.3181e-02, -2.0746e-02,\n",
      "        -5.6909e-02, -2.7961e-02,  4.1631e-02, -6.2309e-02,  2.1797e-02,\n",
      "         2.1057e-03,  1.5406e-02,  3.5755e-02,  2.5454e-02,  3.6064e-02,\n",
      "        -7.2839e-02, -5.1987e-03, -2.2339e-03,  2.5121e-07,  4.4806e-03,\n",
      "         6.2678e-02,  2.3666e-02,  6.4583e-02,  1.7759e-02,  4.1345e-02,\n",
      "        -3.6719e-02,  5.5698e-02, -4.1296e-02,  3.6549e-02,  7.5283e-02,\n",
      "        -3.7279e-02, -2.1201e-02, -1.7645e-02, -2.8843e-02,  2.5682e-02,\n",
      "        -4.9292e-02, -8.7991e-02, -2.8366e-02, -2.1902e-02,  3.7079e-02,\n",
      "         4.1157e-02,  7.8428e-02, -1.4852e-02,  6.1496e-03, -4.0115e-02,\n",
      "        -2.0286e-02, -2.9095e-02,  6.0113e-03,  3.6837e-02,  7.3177e-03,\n",
      "        -8.8180e-03,  4.7030e-03,  3.0126e-02, -3.8254e-03, -6.8149e-03,\n",
      "         3.7234e-02,  8.7899e-02, -2.9022e-03,  3.3346e-02, -3.8454e-02,\n",
      "        -5.7821e-02, -2.7408e-02,  1.4564e-02,  1.5861e-02,  1.8469e-02,\n",
      "         3.5228e-02, -5.6363e-02,  2.0709e-02,  3.2231e-02, -2.9926e-02,\n",
      "         5.9291e-02, -3.0127e-03, -2.2829e-03,  2.8026e-02, -7.5941e-02,\n",
      "         4.0645e-03,  1.2157e-02,  1.2857e-02, -1.7388e-03, -2.9515e-02,\n",
      "         3.7757e-02,  1.9463e-02,  4.8034e-02,  1.5300e-02,  5.0478e-02,\n",
      "        -8.8198e-03,  1.6489e-34,  4.7793e-02, -6.4804e-03, -3.3139e-03,\n",
      "         1.0290e-02, -3.3080e-02, -2.5540e-02,  3.7865e-02, -1.3555e-02,\n",
      "        -8.2793e-03,  2.6527e-02, -2.0190e-03])\n",
      "**********\n",
      "tensor([ 4.1702e-02,  1.0974e-03, -1.5534e-02,  7.0922e-02, -1.7728e-03,\n",
      "         4.6612e-02, -2.1068e-02,  2.1534e-02, -7.5953e-02, -4.8066e-02,\n",
      "        -2.5045e-02,  2.4762e-02,  3.7199e-02, -2.8269e-02,  2.2961e-03,\n",
      "        -4.7332e-02,  6.4223e-02,  9.7513e-03, -4.8339e-02,  5.3801e-03,\n",
      "        -1.9145e-03,  5.2970e-02,  1.8934e-03,  8.1601e-03,  7.3730e-03,\n",
      "        -1.1947e-02,  1.9164e-02, -1.0326e-02,  6.9772e-03,  1.8121e-02,\n",
      "        -5.9703e-02, -7.7189e-03, -2.8897e-02, -2.4192e-02,  1.2549e-06,\n",
      "         1.3595e-02, -7.7575e-02, -3.1764e-02, -2.1125e-02,  2.5717e-02,\n",
      "         2.3769e-02, -3.2400e-02,  8.4897e-03,  3.9815e-02, -6.0308e-02,\n",
      "        -4.0621e-03,  4.8168e-02, -1.0240e-02,  3.3905e-02,  9.2902e-02,\n",
      "        -2.5236e-02, -6.7264e-02, -1.1715e-02, -4.1531e-03,  3.6150e-02,\n",
      "        -2.4459e-02, -2.6550e-02, -3.3190e-04, -1.5853e-02,  8.5590e-02,\n",
      "        -2.6156e-02,  3.9249e-02, -4.8480e-02, -1.8083e-02, -3.5850e-02,\n",
      "        -2.6117e-02,  2.4543e-02, -2.7205e-02,  1.4795e-03, -2.1867e-02,\n",
      "         1.4184e-02, -2.6132e-02,  1.4255e-03,  4.9688e-02,  2.5559e-02,\n",
      "        -6.0035e-02, -7.1631e-02,  5.4161e-02,  1.3836e-02,  2.4777e-02,\n",
      "        -6.2621e-03,  4.0455e-02,  7.1090e-04, -2.0929e-02, -9.4888e-02,\n",
      "         2.0302e-02, -3.0490e-02, -6.3241e-03, -1.5777e-02,  1.5588e-02,\n",
      "        -2.9126e-03, -4.6218e-03,  4.1945e-02, -3.6801e-02,  1.2820e-02,\n",
      "         8.3279e-03, -7.0548e-02, -5.4174e-02, -1.5390e-02, -1.1009e-01,\n",
      "         6.1963e-03,  1.0371e-03,  3.7782e-03, -4.4617e-03, -3.8279e-02,\n",
      "         3.0715e-02,  4.0762e-02, -1.0449e-03, -6.9058e-02,  2.0293e-02,\n",
      "        -4.1289e-02, -2.3131e-02, -7.2215e-02,  6.2882e-02, -4.1585e-03,\n",
      "        -2.4838e-02, -3.3244e-02,  2.5858e-04,  3.5347e-02,  2.7935e-03,\n",
      "        -1.7277e-02, -1.1066e-02, -1.3533e-02,  7.9886e-03,  8.6650e-03,\n",
      "         6.8395e-02,  1.9067e-02,  5.6389e-02, -1.0070e-02, -1.3935e-02,\n",
      "         1.5026e-02,  4.4070e-02,  1.6057e-02,  1.1221e-02, -9.0907e-02,\n",
      "         1.6027e-02, -4.0827e-02,  4.4850e-02,  1.4251e-02, -8.2724e-03,\n",
      "        -4.3608e-02,  6.7876e-03,  2.8756e-04, -3.3303e-02, -4.1911e-04,\n",
      "         4.3252e-02,  4.7147e-02, -5.7708e-02,  4.1104e-02,  2.9818e-02,\n",
      "        -7.9010e-02,  1.2345e-01, -2.0417e-03, -1.0306e-02,  1.1222e-02,\n",
      "        -5.1473e-02,  5.3790e-02,  1.6528e-02,  4.4121e-02,  1.1866e-02,\n",
      "         3.3692e-02, -1.0085e-02,  2.1958e-02,  4.5034e-02, -2.9122e-02,\n",
      "         1.5969e-02, -5.6713e-02, -1.3281e-02,  2.1390e-02,  1.7627e-02,\n",
      "         3.9551e-02,  6.2046e-02,  2.4838e-02,  2.8973e-02, -4.6818e-03,\n",
      "         4.8784e-02,  3.9571e-03,  1.9647e-02,  4.1112e-03,  5.7889e-03,\n",
      "         4.3193e-04,  3.1830e-02, -4.3198e-02, -4.5035e-02, -2.0148e-02,\n",
      "        -1.7777e-02,  1.8025e-02,  4.9865e-03,  2.4831e-02,  1.3618e-02,\n",
      "        -1.2330e-02,  4.2588e-02,  4.4484e-03, -4.6208e-02, -2.8820e-02,\n",
      "         5.5779e-02, -4.0632e-02,  6.1058e-02, -1.7604e-02, -5.5482e-02,\n",
      "         3.7941e-02,  5.9698e-03, -3.2125e-03,  1.7144e-02,  8.3871e-03,\n",
      "         3.7987e-02,  4.8243e-02, -5.8772e-02, -1.7848e-02,  5.5597e-02,\n",
      "        -1.8093e-02,  3.0070e-02, -1.8290e-02, -5.2135e-03, -1.7818e-03,\n",
      "         1.7427e-02,  1.7752e-02, -6.2949e-05, -8.2159e-02,  1.5750e-02,\n",
      "         4.2982e-02, -3.1593e-02, -8.4011e-03,  1.5776e-02,  3.3935e-02,\n",
      "         1.9929e-02,  9.5932e-03,  1.4231e-02, -2.7462e-02, -1.7656e-02,\n",
      "        -3.1776e-03,  5.4493e-02,  1.8370e-02, -2.5745e-02, -4.3765e-02,\n",
      "         7.5201e-02, -3.8277e-02, -1.2813e-01, -7.2389e-03, -3.7385e-02,\n",
      "         5.5497e-02,  7.5128e-03,  3.1986e-02, -2.2709e-02,  1.2622e-03,\n",
      "        -8.7633e-03,  4.8371e-02,  1.4078e-02,  5.4932e-02, -8.7866e-03,\n",
      "         4.1534e-02, -3.8852e-02, -2.2713e-02, -9.7040e-04, -2.7608e-02,\n",
      "        -2.9964e-02, -4.0085e-02,  5.8536e-02,  1.0262e-02,  4.4740e-02,\n",
      "         7.2741e-02, -4.7355e-03, -1.9333e-02,  3.4302e-02, -2.5887e-02,\n",
      "         1.8930e-02, -3.5922e-02, -2.5786e-02, -2.9347e-02,  1.0678e-02,\n",
      "         4.9688e-02,  3.9968e-02,  5.3009e-02,  1.1589e-02,  1.0939e-02,\n",
      "        -1.6925e-02,  3.1479e-02,  3.0374e-02, -6.0429e-03,  1.1985e-03,\n",
      "         3.8016e-03,  4.7030e-02, -2.6175e-02, -4.8210e-03, -1.8147e-02,\n",
      "         4.3843e-02, -2.1747e-02, -8.6786e-02, -6.4662e-02,  6.9332e-02,\n",
      "         4.6670e-02,  5.5158e-04,  5.6655e-02, -7.1776e-02,  1.4347e-02,\n",
      "        -1.7347e-02,  6.6510e-02,  1.8271e-02,  2.8810e-02,  5.3632e-02,\n",
      "        -1.9629e-02, -1.4507e-04, -4.0739e-02, -2.0107e-02,  1.0796e-02,\n",
      "        -2.8598e-02, -5.4662e-02, -7.8073e-02,  1.3864e-02,  6.4883e-03,\n",
      "         8.6878e-02,  3.7808e-02, -3.6864e-02, -5.9546e-03, -5.4935e-02,\n",
      "         1.7887e-02, -4.8450e-02,  1.0110e-02, -1.2997e-02, -1.3286e-03,\n",
      "         1.7796e-02,  5.7516e-02, -3.3532e-02, -1.9452e-02,  4.7739e-03,\n",
      "        -3.3155e-02,  1.0271e-02,  7.4529e-03,  1.5707e-02, -6.6638e-03,\n",
      "         3.1398e-02, -1.3652e-02, -6.3288e-02, -2.6445e-02,  3.8767e-03,\n",
      "        -1.5030e-02,  1.3112e-04,  5.5362e-02,  1.2219e-02,  1.2649e-02,\n",
      "        -3.6206e-02, -3.9330e-02,  1.1660e-02, -5.1849e-02, -2.1605e-02,\n",
      "         9.7189e-03,  1.5127e-02, -2.4210e-02, -7.1213e-02,  1.2818e-02,\n",
      "         2.7607e-02, -1.8966e-02, -5.4743e-02, -1.5632e-02, -3.0944e-02,\n",
      "         3.3276e-02,  1.1765e-02, -4.3823e-02, -9.0858e-03, -5.5012e-02,\n",
      "         3.8618e-02,  2.8892e-02, -5.1899e-02,  3.5711e-02, -1.3285e-02,\n",
      "        -7.3059e-03, -1.5654e-02,  1.9765e-02, -5.5359e-02,  2.7229e-04,\n",
      "         1.3297e-02, -4.9983e-03,  6.6916e-03,  6.6781e-02, -1.5398e-02,\n",
      "        -2.2808e-02,  2.0294e-02, -2.2382e-02, -4.9383e-02, -1.3961e-02,\n",
      "         2.7452e-02, -1.0941e-01, -4.3161e-03, -9.9238e-03,  1.9551e-02,\n",
      "         2.8555e-02,  1.3646e-02, -1.3163e-02, -8.2784e-02,  1.4571e-03,\n",
      "         5.9283e-02, -5.2036e-02, -5.0629e-02,  3.0048e-02, -1.4539e-02,\n",
      "         3.3317e-02,  3.2268e-02,  2.3856e-02,  6.4706e-03,  1.9073e-02,\n",
      "         1.2168e-02,  5.4778e-02,  5.0340e-02, -6.1447e-02,  5.3847e-02,\n",
      "         6.8771e-02,  5.0974e-02,  2.6986e-02, -9.3328e-02, -4.3768e-03,\n",
      "         2.6063e-02, -2.0515e-02, -4.0361e-03, -6.6232e-03,  2.4106e-03,\n",
      "         4.9318e-02, -1.6343e-03,  6.8015e-02, -6.1259e-03, -2.0311e-02,\n",
      "        -3.1595e-02,  5.7611e-02,  1.9925e-02, -3.9470e-02, -2.9003e-02,\n",
      "        -1.7333e-02,  5.7816e-02, -6.9513e-03,  1.8074e-02, -5.2435e-03,\n",
      "        -4.1019e-03,  1.9575e-02, -8.0617e-02, -4.6544e-02, -6.0449e-02,\n",
      "        -4.5746e-02,  1.3196e-02, -5.1861e-02, -3.2243e-03, -8.3628e-02,\n",
      "         4.2921e-03, -1.3558e-02,  3.5969e-02,  4.1509e-03, -2.2661e-02,\n",
      "         5.5555e-02,  8.5237e-03,  2.2123e-02, -3.0390e-02,  1.1820e-02,\n",
      "         3.5268e-02, -6.1328e-02, -2.2006e-02,  4.1580e-02,  1.6747e-02,\n",
      "         3.8022e-02, -7.1780e-02, -5.7601e-02, -1.6789e-02,  5.2850e-03,\n",
      "         3.0290e-02,  2.8664e-02, -3.1603e-02, -8.4580e-03, -1.4180e-02,\n",
      "        -2.9434e-02,  5.2078e-02, -3.3713e-02,  3.2655e-02,  1.6655e-02,\n",
      "         3.8127e-03, -1.5713e-03,  1.4602e-02,  4.0858e-02,  2.3675e-02,\n",
      "        -2.5467e-02, -2.0942e-02, -4.7630e-02, -7.3440e-02,  1.9551e-02,\n",
      "         9.2403e-03, -3.2398e-02, -5.2240e-03,  8.6144e-03,  3.4260e-02,\n",
      "        -3.4612e-02, -4.9137e-02, -1.9238e-02, -2.8087e-02,  2.6586e-02,\n",
      "         6.3328e-02,  4.5816e-02,  9.6207e-03,  2.2392e-03, -8.9822e-03,\n",
      "        -5.0880e-02,  1.8680e-02, -5.0380e-02,  4.3872e-02, -9.5719e-03,\n",
      "         1.7840e-02,  2.6608e-02, -1.2240e-03,  3.7199e-02,  1.4946e-02,\n",
      "         2.7483e-02, -1.6858e-02,  1.5643e-02,  8.1433e-03,  1.1514e-02,\n",
      "        -3.8894e-02,  7.6020e-03, -2.9560e-02,  2.0957e-02, -1.2105e-03,\n",
      "         8.4981e-03,  1.0092e-02,  1.3009e-03,  6.1160e-02,  1.5643e-02,\n",
      "         2.0484e-02, -6.8433e-03,  2.5219e-02, -2.6296e-02,  4.6341e-02,\n",
      "        -3.2582e-02, -5.5203e-02, -6.1372e-03, -3.0553e-02,  5.9876e-02,\n",
      "        -8.4744e-02, -6.6649e-03,  3.1099e-02, -6.5667e-02, -1.1031e-02,\n",
      "        -7.4607e-03, -8.8307e-03, -3.3432e-02,  2.3043e-02, -1.2839e-02,\n",
      "         6.8364e-02, -2.2200e-02,  2.2839e-02, -3.6359e-03,  5.4284e-02,\n",
      "        -1.3965e-02,  3.6578e-03,  3.0586e-02, -1.0573e-02, -2.9524e-02,\n",
      "        -3.8064e-02,  6.6523e-02,  2.1347e-02,  2.0866e-02, -2.5624e-02,\n",
      "        -5.0561e-33, -4.5583e-02,  1.3759e-02, -3.7182e-02,  3.7114e-02,\n",
      "        -2.2224e-02, -4.5303e-02, -1.6872e-02,  4.7727e-02,  2.0528e-02,\n",
      "         4.7939e-02, -2.7527e-02,  1.1011e-02,  3.0598e-02, -1.1548e-02,\n",
      "         6.5743e-02,  2.2911e-02,  4.4906e-02, -3.9937e-02, -2.1915e-02,\n",
      "         5.8005e-03,  3.6271e-02, -1.0139e-02,  5.9605e-02, -4.6725e-02,\n",
      "        -2.1742e-02,  3.5256e-02, -8.0854e-02,  6.1635e-03,  3.6826e-02,\n",
      "         3.5223e-03,  1.3452e-02,  1.5148e-02, -1.0052e-02, -3.3175e-03,\n",
      "        -5.2070e-02,  8.8622e-02, -4.1415e-02, -1.5143e-02,  1.7959e-02,\n",
      "         6.4899e-02, -1.0535e-02, -3.8296e-02,  3.1511e-02, -3.3964e-02,\n",
      "         1.5202e-02,  8.8238e-03, -9.2812e-03, -5.4699e-02,  2.0004e-02,\n",
      "        -1.9975e-02, -5.4450e-02, -1.9729e-02,  7.7343e-03,  2.6952e-02,\n",
      "         1.4669e-02,  6.9363e-02, -5.3559e-02, -3.3113e-02, -4.0665e-03,\n",
      "         4.2480e-02,  5.9841e-02,  8.5679e-02, -1.5351e-02, -7.4234e-03,\n",
      "        -5.5146e-02, -4.4653e-02, -2.1069e-03, -9.8621e-03, -3.4445e-02,\n",
      "         7.0750e-02,  2.2847e-02,  4.4835e-02,  1.2513e-02,  6.0383e-02,\n",
      "        -6.4036e-03, -3.4918e-02, -2.1753e-02,  2.4427e-02,  1.1596e-02,\n",
      "        -1.8665e-02, -1.5401e-02,  3.4739e-02,  5.4022e-02, -4.6038e-02,\n",
      "        -2.1940e-02,  3.0296e-02,  2.3473e-02, -3.3154e-02,  1.4215e-02,\n",
      "        -3.4114e-02,  1.2919e-02, -2.5782e-03,  4.6136e-02, -6.1360e-02,\n",
      "        -6.5423e-02,  1.2367e-02, -6.9521e-02,  1.2181e-02, -4.9106e-02,\n",
      "         3.4104e-02, -5.7831e-03, -5.4102e-02,  1.0173e-02, -3.3902e-02,\n",
      "         2.7045e-02,  5.6944e-02,  1.8220e-02, -1.7916e-03, -5.1380e-02,\n",
      "        -2.0867e-02,  1.8661e-02, -4.8399e-03,  6.3537e-03,  5.6674e-02,\n",
      "        -2.9997e-02, -1.2917e-02,  1.9420e-02, -1.6806e-02, -1.0994e-02,\n",
      "        -3.0055e-02,  2.5895e-02, -7.6691e-03,  2.6324e-02,  4.9940e-02,\n",
      "        -9.0214e-02, -1.3945e-02, -6.6698e-02,  3.2248e-02,  2.0390e-02,\n",
      "        -6.1215e-02, -1.9253e-02,  8.6807e-03,  1.9573e-07,  5.9598e-02,\n",
      "         4.0408e-02, -4.1038e-03, -1.7902e-02,  4.8509e-03,  5.4592e-03,\n",
      "        -1.0314e-02,  5.1554e-02,  1.2235e-02,  5.6371e-02, -1.6862e-02,\n",
      "        -5.2449e-02,  5.1521e-02, -4.5415e-03, -3.2334e-02, -1.6578e-02,\n",
      "        -1.1487e-02, -4.7395e-02, -4.7399e-02,  1.9810e-02,  8.9734e-02,\n",
      "         6.4397e-02,  1.3868e-02,  2.6077e-02, -1.6788e-03, -8.6896e-03,\n",
      "        -4.1652e-03, -8.5931e-03,  2.5708e-03,  6.5115e-03, -4.5601e-03,\n",
      "        -5.2364e-02, -2.1852e-02,  1.6304e-03, -1.7235e-03,  3.2590e-03,\n",
      "         6.2532e-02,  4.2110e-02,  6.9947e-04,  5.8350e-02, -2.7586e-02,\n",
      "        -3.4463e-02, -1.4316e-02, -1.4857e-02,  2.6549e-03, -1.5162e-02,\n",
      "         2.6052e-02,  1.3981e-02, -1.8785e-03,  2.8284e-02, -2.7880e-02,\n",
      "         9.3716e-03, -4.2472e-04,  3.0220e-03,  5.3931e-02,  1.1338e-02,\n",
      "        -6.8786e-03, -4.8500e-02, -4.0443e-02, -2.4179e-02, -2.2661e-02,\n",
      "         1.9207e-02,  1.9934e-02,  4.4995e-02, -6.2405e-03, -1.5456e-02,\n",
      "         5.0875e-03,  1.6338e-34,  2.3620e-02, -2.9326e-03,  4.2650e-02,\n",
      "         1.2357e-02,  3.1967e-03, -1.3879e-02,  2.6863e-02,  5.3636e-02,\n",
      "        -2.1816e-02, -6.3594e-02, -8.7528e-03])\n",
      "**********\n",
      "tensor([ 4.1577e-02, -7.3413e-03, -2.8671e-02,  3.0352e-02, -7.1073e-02,\n",
      "         3.1576e-02,  1.8696e-02,  3.2533e-02,  2.6017e-02, -4.9748e-02,\n",
      "         1.9409e-02,  1.2741e-02,  3.8211e-02, -2.6269e-02,  2.4938e-02,\n",
      "        -3.6343e-02,  8.3726e-02,  1.0761e-02,  4.6944e-02,  2.3011e-02,\n",
      "        -9.0374e-03,  4.8592e-02, -2.6333e-02,  1.0549e-02, -4.8587e-02,\n",
      "        -3.5472e-02,  1.8806e-02, -4.5401e-02,  1.6909e-02, -3.9118e-02,\n",
      "         4.5107e-02,  5.6860e-02, -3.9658e-02, -3.4787e-02,  1.3551e-06,\n",
      "         4.3172e-03, -2.7817e-02, -4.8941e-02, -5.0763e-02, -1.0336e-02,\n",
      "        -5.2999e-02,  5.4814e-02, -4.2367e-03, -8.9170e-03, -3.2101e-03,\n",
      "         1.8126e-02,  3.3031e-02,  8.2493e-02,  4.3944e-03,  4.1126e-02,\n",
      "        -4.6316e-03, -7.3101e-02, -8.2168e-03, -2.4599e-02,  6.9575e-02,\n",
      "        -1.9008e-02,  4.0094e-02, -1.6160e-02, -1.5179e-02,  4.3417e-02,\n",
      "         2.0598e-02,  9.3072e-03, -3.3881e-02,  1.3997e-02,  1.6343e-02,\n",
      "        -8.4866e-03, -2.0454e-02, -4.2459e-02, -2.3160e-03,  2.9545e-02,\n",
      "        -1.1406e-03, -1.1080e-02,  1.2025e-02,  3.9514e-02,  2.7506e-02,\n",
      "        -7.6520e-02, -3.7695e-03,  3.9117e-02,  3.7173e-03,  1.9906e-02,\n",
      "         5.5437e-02,  1.0861e-01,  6.1135e-03, -1.0041e-03, -4.3562e-03,\n",
      "        -1.7269e-02,  9.7201e-03,  1.1681e-02, -5.2064e-02, -4.4400e-02,\n",
      "        -8.0217e-02, -1.2498e-02,  1.4926e-02,  8.2246e-03,  1.1160e-02,\n",
      "         1.1575e-02, -1.0382e-01, -6.4354e-02,  2.2974e-02, -8.6877e-02,\n",
      "         3.0343e-02, -4.4701e-02,  2.4191e-04,  2.1815e-02, -1.4072e-02,\n",
      "         8.7737e-04,  5.2876e-02,  4.2776e-02, -6.4101e-02,  1.3653e-02,\n",
      "        -5.4772e-02, -5.8150e-02, -8.4804e-02,  1.0670e-01,  5.6153e-02,\n",
      "        -4.1617e-02, -5.6482e-02,  3.0582e-02,  1.9576e-02,  4.3547e-03,\n",
      "        -1.0154e-01,  2.3576e-02, -2.8721e-02,  4.2832e-02,  7.8311e-03,\n",
      "        -4.8377e-03, -2.0652e-02,  3.7337e-02,  1.7059e-02, -3.7502e-02,\n",
      "         2.3458e-02,  2.2793e-02,  4.2577e-02, -1.9710e-02, -3.7088e-02,\n",
      "         2.9365e-02,  2.4695e-02, -3.2463e-02, -4.7531e-02, -1.6805e-02,\n",
      "         6.5728e-03, -4.5567e-02, -3.4313e-02, -4.7458e-02, -2.0044e-02,\n",
      "         5.8287e-02, -1.1599e-02, -9.9118e-02,  3.6831e-02,  1.6086e-02,\n",
      "        -3.6829e-02,  5.1125e-02, -3.5637e-03, -2.3306e-02, -3.3102e-02,\n",
      "        -1.7466e-02,  1.5689e-01, -1.0957e-02,  1.5025e-02, -2.6757e-02,\n",
      "         3.5294e-02, -6.6750e-03,  1.1730e-02, -1.3166e-02, -3.5091e-02,\n",
      "        -5.3480e-04, -1.7811e-02, -3.6192e-02,  1.9680e-02,  1.8361e-02,\n",
      "        -5.6906e-02,  4.6623e-02,  8.3533e-03,  4.5491e-02,  3.7802e-02,\n",
      "         9.1772e-02, -2.6002e-02,  6.8873e-03, -7.1559e-02,  3.6361e-02,\n",
      "        -6.5247e-03,  2.3673e-02,  4.3824e-02,  2.3670e-02,  1.9838e-03,\n",
      "         6.5710e-03,  3.9371e-02, -2.3821e-02, -1.7772e-02, -4.1784e-02,\n",
      "        -4.0355e-02,  3.5586e-02, -1.9131e-02, -2.9202e-02, -1.4263e-02,\n",
      "         4.2309e-02, -1.5861e-02,  7.0241e-02, -1.2855e-02, -3.8584e-02,\n",
      "        -1.1965e-02,  3.9685e-02,  4.3254e-02,  7.2917e-03, -1.5080e-02,\n",
      "        -2.0548e-02,  7.5678e-03, -4.4189e-02,  5.7242e-02,  2.0193e-02,\n",
      "         8.0231e-02,  9.2490e-03, -1.7715e-02, -1.2569e-03,  2.5644e-02,\n",
      "         2.6956e-02,  2.8185e-02, -1.2949e-02, -6.0429e-02,  1.7227e-02,\n",
      "        -8.9859e-03,  1.3873e-02,  3.7197e-03,  1.5837e-02,  2.1549e-02,\n",
      "        -6.8486e-02, -1.9870e-02, -1.7242e-02, -1.4209e-02, -1.4511e-02,\n",
      "        -8.1214e-03,  4.5852e-02,  1.9759e-02,  5.4725e-03, -4.4211e-02,\n",
      "         2.4327e-02,  2.4498e-02, -4.3595e-02, -1.8261e-02, -1.8737e-02,\n",
      "        -1.6654e-02, -3.5715e-02,  2.5129e-02, -1.7251e-02,  3.8886e-02,\n",
      "        -1.5092e-02, -1.2114e-02,  8.5062e-04,  2.3455e-02,  5.4198e-03,\n",
      "         3.1397e-02, -2.8800e-02,  3.5048e-02,  1.1597e-02,  4.8566e-02,\n",
      "        -9.7099e-02,  9.6584e-03,  5.0018e-02, -2.7453e-02,  4.1930e-02,\n",
      "         4.1308e-02, -2.0003e-02,  8.3515e-03, -1.1835e-02, -1.9439e-02,\n",
      "         2.5880e-02, -3.9275e-02, -1.0738e-02, -1.9572e-02,  1.1582e-02,\n",
      "        -2.4240e-02, -4.7290e-03,  5.5726e-02,  4.8609e-04,  1.8437e-02,\n",
      "         7.5646e-03, -3.9417e-02,  1.8420e-02,  3.5219e-03,  5.9998e-02,\n",
      "         5.4576e-03, -4.5835e-02, -1.5642e-02,  1.6227e-02, -3.3441e-02,\n",
      "         4.1953e-02, -1.0534e-02, -7.2864e-02, -9.3866e-03, -1.1660e-02,\n",
      "         3.3824e-02,  3.8294e-02, -3.4963e-04, -4.8037e-02,  4.1556e-02,\n",
      "         1.9173e-02,  3.1231e-02, -2.6716e-03,  5.1444e-02,  3.4487e-02,\n",
      "        -5.8620e-02, -3.5368e-02,  2.1545e-03, -3.5474e-02, -4.6734e-03,\n",
      "         5.1777e-02,  4.0625e-03, -9.0388e-03,  4.9531e-03,  2.9550e-02,\n",
      "         8.4686e-02,  4.1515e-03,  1.3705e-02,  7.0008e-02,  4.7311e-03,\n",
      "         3.1594e-02, -6.5952e-02, -8.9387e-03, -2.2777e-02, -2.8552e-02,\n",
      "         3.5116e-05, -2.1576e-03,  1.1516e-02,  1.2130e-03,  2.9023e-02,\n",
      "        -6.7042e-02, -1.2427e-02,  1.7329e-02,  3.1176e-02, -5.5259e-03,\n",
      "         2.1151e-02, -2.7901e-03, -3.1775e-03,  2.9446e-02,  3.6737e-02,\n",
      "         1.0358e-02,  1.3964e-02, -2.9645e-02, -1.9765e-02,  9.1146e-03,\n",
      "        -1.6804e-02, -6.2108e-03, -7.8682e-03, -2.6605e-02,  8.0653e-03,\n",
      "         7.3690e-03,  4.2135e-02,  3.1092e-03, -2.4081e-02, -3.1789e-04,\n",
      "         3.1593e-02, -1.4551e-03, -2.6822e-02,  2.6774e-02, -5.9180e-02,\n",
      "        -3.3931e-03,  4.6518e-02, -5.0213e-02, -2.6182e-02, -2.1344e-02,\n",
      "         2.4548e-02, -1.1739e-02,  1.0791e-02,  2.8881e-02, -2.9835e-02,\n",
      "         7.7949e-03, -2.8838e-03, -5.4200e-02, -1.4849e-02, -1.4097e-02,\n",
      "        -8.3660e-03, -4.4051e-04, -1.7074e-02,  4.5520e-02, -9.3774e-03,\n",
      "        -1.7712e-02,  4.9978e-02,  3.3081e-03, -7.5974e-02,  1.8680e-02,\n",
      "         7.7841e-03, -5.6220e-02, -7.6321e-03, -1.4386e-02, -8.0620e-02,\n",
      "        -9.2813e-03, -2.6734e-03, -4.3816e-02, -3.4496e-02,  2.2749e-02,\n",
      "         3.7167e-02, -5.2005e-02, -1.1193e-01,  2.7567e-02, -3.3726e-02,\n",
      "         4.0758e-02,  6.7306e-03,  5.1975e-02, -2.8533e-02,  9.6359e-03,\n",
      "         2.3754e-02,  4.0060e-02, -8.0746e-03, -3.9624e-02, -2.5459e-02,\n",
      "        -1.2191e-02,  3.0655e-02,  2.2382e-02, -6.3905e-02, -3.7597e-02,\n",
      "         3.2028e-02, -3.7588e-02, -3.0650e-02,  1.7792e-02,  6.7222e-02,\n",
      "        -3.7944e-02, -9.4219e-03, -1.7038e-02, -7.3732e-03, -4.1306e-02,\n",
      "        -3.9189e-02,  1.7570e-02,  3.4967e-02, -6.3474e-02, -2.8788e-03,\n",
      "         8.2554e-03, -2.9701e-02, -2.8269e-03,  3.5723e-03, -6.4597e-03,\n",
      "         1.6054e-02, -2.8689e-02, -2.0675e-02,  9.3607e-03, -7.5020e-02,\n",
      "        -3.6602e-02, -5.2653e-03, -4.2367e-02,  1.9885e-03, -8.0668e-02,\n",
      "        -3.4392e-02,  7.8042e-03,  4.6704e-02,  2.0478e-02,  1.7637e-02,\n",
      "        -3.2031e-02, -4.6057e-02,  2.3352e-03,  1.4962e-02,  5.5847e-02,\n",
      "         2.8278e-02, -4.7265e-02, -1.3122e-02,  3.5434e-02,  6.8499e-02,\n",
      "        -1.1330e-02, -2.0198e-02, -1.1199e-02, -1.0814e-02,  2.3410e-02,\n",
      "         1.4780e-02,  2.5593e-02, -4.0735e-02, -2.6914e-02, -9.8707e-03,\n",
      "        -6.4403e-02, -8.5306e-03,  4.6060e-02, -4.2606e-03, -4.5643e-03,\n",
      "        -2.9417e-02,  1.3235e-02,  1.0759e-02,  6.2997e-03,  4.3924e-02,\n",
      "        -3.1509e-02, -3.1334e-02, -3.8302e-02, -6.9828e-02,  1.6128e-02,\n",
      "         1.9161e-02,  3.6417e-03,  1.9288e-02, -4.9038e-03,  8.4258e-03,\n",
      "        -1.6197e-02, -2.5763e-03, -5.9481e-02,  1.8181e-02,  2.2061e-02,\n",
      "         6.2584e-03,  5.6080e-02, -2.4447e-02, -1.6426e-03, -1.5775e-02,\n",
      "         9.1678e-04,  4.5093e-02,  3.5762e-02,  4.8300e-02, -3.4144e-02,\n",
      "        -3.1736e-02, -1.5477e-02,  1.0837e-02,  3.8115e-02, -2.2266e-02,\n",
      "         4.4931e-02,  3.4500e-03, -1.6957e-03,  2.1585e-02, -3.5395e-02,\n",
      "        -2.8260e-02,  2.6648e-02,  3.2469e-02,  5.2211e-02, -1.5931e-02,\n",
      "        -1.2369e-02, -4.5557e-03, -2.9576e-02, -4.1332e-02,  1.3179e-02,\n",
      "         2.5078e-03, -1.6595e-02,  4.4548e-02, -3.8061e-02, -3.1950e-02,\n",
      "        -6.9852e-03,  2.3911e-02, -1.7305e-02, -3.2580e-02,  4.3638e-02,\n",
      "         1.1197e-02,  4.4355e-03, -1.7669e-02,  2.9398e-03, -5.2261e-02,\n",
      "         5.8439e-02,  3.9699e-02,  3.0018e-02,  3.0752e-02, -6.9006e-04,\n",
      "         7.0507e-03,  3.1880e-03,  6.6823e-02, -8.0278e-03,  1.0579e-01,\n",
      "         2.3574e-02, -1.6871e-02,  4.2045e-02, -5.1519e-03, -5.6326e-02,\n",
      "        -6.0761e-02,  3.5686e-02, -7.8154e-02,  6.1620e-03, -1.4594e-02,\n",
      "        -5.2165e-33, -5.9067e-02, -3.5018e-02, -2.1851e-02,  1.2061e-02,\n",
      "         2.8160e-02, -2.7998e-02, -1.1796e-02,  4.0848e-02,  2.9579e-02,\n",
      "         3.0774e-02, -4.4397e-03,  3.0564e-03,  4.0033e-02,  1.8634e-02,\n",
      "         5.8633e-02,  3.2392e-03,  1.8993e-02, -7.6087e-03, -8.0776e-03,\n",
      "        -3.7810e-02,  8.4706e-03,  1.5601e-02,  1.3640e-01,  1.6886e-02,\n",
      "         1.0492e-02, -5.0826e-03, -4.6140e-03, -1.7065e-02, -3.3210e-02,\n",
      "         1.1376e-02, -3.6382e-02,  8.4372e-03, -9.9459e-03,  3.6953e-02,\n",
      "        -1.4726e-02,  7.5314e-02, -1.5296e-02, -7.6894e-02, -8.9730e-03,\n",
      "         4.9806e-02, -3.7625e-02, -1.1033e-01,  1.3174e-02, -6.2342e-02,\n",
      "         1.8798e-02,  4.8464e-02,  2.8739e-02, -2.1135e-02,  1.2082e-02,\n",
      "         2.5001e-02, -2.9996e-02, -8.2457e-03,  1.3555e-03,  4.4342e-03,\n",
      "        -3.3398e-02, -3.7860e-02, -2.8301e-02,  1.0260e-02, -4.5323e-02,\n",
      "         1.1302e-03,  1.2700e-02,  7.5813e-02, -4.3072e-02, -7.7440e-03,\n",
      "        -1.7892e-02,  2.5358e-02,  1.0554e-02, -4.7947e-03, -7.7932e-03,\n",
      "         1.0662e-01, -1.1340e-02,  1.0187e-01,  5.8789e-02,  2.2321e-02,\n",
      "        -3.1412e-03, -3.1744e-02,  1.2330e-02,  1.1331e-02,  5.4634e-02,\n",
      "        -3.3932e-02,  5.0532e-02,  2.1216e-02, -5.1755e-02, -1.3606e-02,\n",
      "        -8.3812e-03, -6.4743e-02,  1.0905e-02,  3.8513e-02,  7.8024e-03,\n",
      "        -1.4052e-02, -5.2734e-03,  2.8478e-02,  2.7559e-02, -3.9692e-03,\n",
      "        -1.0150e-01,  3.7801e-03, -5.3183e-03,  1.3693e-02, -3.0539e-02,\n",
      "         1.6323e-03, -2.6195e-02, -7.4597e-02,  6.9259e-03,  3.9100e-02,\n",
      "         5.0493e-02,  2.1502e-02,  1.9200e-03, -2.5322e-02, -7.6928e-02,\n",
      "        -2.9001e-02, -1.6935e-03, -1.6405e-02,  1.6993e-02, -3.1737e-02,\n",
      "        -1.2480e-02, -6.7373e-03, -1.6484e-03, -1.4947e-02, -1.4731e-02,\n",
      "        -2.4866e-02, -9.7364e-03,  1.2064e-02, -1.1123e-01, -8.1680e-03,\n",
      "        -3.6652e-04, -6.8392e-03, -3.2717e-02,  5.8836e-02, -5.6188e-03,\n",
      "        -1.8333e-02,  2.9291e-02,  3.1629e-02,  2.1368e-07, -1.9931e-03,\n",
      "         4.7153e-02,  4.5122e-02, -8.7748e-03, -8.1138e-03,  1.9702e-02,\n",
      "         2.5712e-02,  1.4716e-02, -5.6345e-02,  1.3664e-02,  1.4963e-02,\n",
      "        -2.7902e-02, -1.4168e-02, -2.8218e-02, -5.5950e-02,  1.3984e-02,\n",
      "         1.4237e-03,  2.8733e-02, -4.2455e-02, -2.5465e-02, -4.0214e-03,\n",
      "         7.0374e-02,  6.6576e-02,  2.8168e-02, -2.2667e-02, -4.8092e-02,\n",
      "        -4.9696e-02,  3.2232e-02,  4.7555e-03,  3.7074e-02,  6.8301e-02,\n",
      "        -2.0221e-02,  9.0492e-03,  7.6681e-02,  7.5851e-04,  8.7557e-03,\n",
      "         6.4861e-02,  2.7878e-02, -6.0334e-03,  6.0076e-02, -2.9098e-02,\n",
      "        -7.7851e-02, -1.5745e-02,  4.2030e-02,  5.7009e-02, -2.5228e-02,\n",
      "         4.9072e-03, -1.6092e-02, -4.5680e-02,  1.3814e-02,  9.4716e-03,\n",
      "         7.3586e-02, -5.0437e-03,  2.5081e-02,  1.1777e-02, -3.2761e-02,\n",
      "         7.5090e-03, -4.1752e-02,  5.9840e-03,  2.6088e-02, -2.7471e-02,\n",
      "         3.3920e-02,  2.9023e-02,  1.7542e-02,  3.5933e-02,  2.5163e-02,\n",
      "        -1.9603e-02,  1.5663e-34,  4.8449e-02, -3.2784e-02, -1.0249e-02,\n",
      "         2.3561e-02,  1.1545e-02, -1.9596e-02, -5.5085e-02,  3.7068e-02,\n",
      "        -1.1965e-03,  5.7793e-03,  3.1623e-02])\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for i in sentence_embeddings:\n",
    "    print(i)\n",
    "    print(5*\"**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ef6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer output\n",
      "input_ids\n",
      "tensor([[   0, 2027, 2007, 2023, 2746, 6255,    2,    1,    1,    1],\n",
      "        [   0, 2173, 6255, 2007, 4995,    2,    1,    1,    1,    1],\n",
      "        [   0, 6255, 2007, 2746, 2012, 2173, 2777, 3142, 8913,    2]])\n",
      "attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "**************************************************\n",
      "Compute token embeddings\n",
      "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 9.6638e-02, -1.7067e-01,  7.6037e-03,  ...,  2.3386e-02,\n",
      "           1.0138e-01, -4.2516e-02],\n",
      "         [ 6.8078e-02, -1.5394e-01, -1.2517e-01,  ..., -1.1160e-02,\n",
      "           1.1047e-02, -1.3179e-03],\n",
      "         [ 1.5145e-02, -3.7817e-01, -1.0184e-01,  ..., -8.7419e-02,\n",
      "           1.0200e-01,  7.7285e-02],\n",
      "         ...,\n",
      "         [ 5.1867e-02,  2.4321e-01, -5.4224e-02,  ...,  8.1914e-02,\n",
      "           6.1595e-02, -2.0032e-02],\n",
      "         [ 5.6142e-02,  1.7018e-01, -3.4386e-02,  ...,  7.2115e-02,\n",
      "           8.5391e-02, -2.3103e-02],\n",
      "         [ 6.2897e-02,  1.3496e-01, -1.5203e-02,  ...,  7.7281e-02,\n",
      "           8.9326e-02, -2.7996e-02]],\n",
      "\n",
      "        [[ 1.2760e-01,  2.1539e-02, -4.1318e-02,  ..., -1.0661e-01,\n",
      "          -1.9259e-01, -5.4022e-03],\n",
      "         [ 1.4989e-01, -7.3534e-03, -9.6599e-02,  ..., -8.0247e-02,\n",
      "          -3.2525e-01, -1.0300e-04],\n",
      "         [ 2.1020e-01,  7.2042e-02, -3.7893e-02,  ...,  3.0247e-02,\n",
      "          -3.0968e-01,  1.3309e-02],\n",
      "         ...,\n",
      "         [ 1.4586e-01,  1.2561e-01, -6.8405e-02,  ..., -5.9314e-02,\n",
      "          -1.8956e-01, -3.5895e-02],\n",
      "         [ 1.5359e-01,  1.1931e-01, -6.4013e-02,  ..., -4.8962e-02,\n",
      "          -1.7586e-01, -3.9442e-02],\n",
      "         [ 1.5763e-01,  1.1675e-01, -6.1009e-02,  ..., -4.4328e-02,\n",
      "          -1.7344e-01, -4.2663e-02]],\n",
      "\n",
      "        [[ 1.2773e-01,  1.6627e-02, -1.9392e-02,  ..., -3.8586e-02,\n",
      "          -1.7089e-02,  6.0236e-02],\n",
      "         [ 1.4204e-01,  4.8113e-02, -8.9539e-02,  ...,  7.6166e-02,\n",
      "          -1.5577e-01,  1.4245e-01],\n",
      "         [ 9.2776e-02, -1.0372e-01, -1.4182e-01,  ..., -4.2300e-02,\n",
      "          -1.9185e-02,  9.3839e-02],\n",
      "         ...,\n",
      "         [ 1.1859e-01, -1.2946e-01, -6.1840e-02,  ...,  2.5068e-02,\n",
      "           1.2239e-01,  1.6179e-01],\n",
      "         [ 1.0856e-01,  2.0137e-01, -1.1104e-01,  ..., -1.0351e-02,\n",
      "           6.2995e-02,  1.3075e-01],\n",
      "         [ 8.1409e-02, -5.0374e-02, -5.6444e-02,  ...,  2.2224e-02,\n",
      "           8.4361e-02,  7.2385e-02]]]), pooler_output=tensor([[ 0.0880, -0.0418,  0.0182,  ...,  0.0867, -0.0284, -0.0387],\n",
      "        [-0.0302, -0.0482, -0.0346,  ...,  0.0619, -0.0250,  0.0269],\n",
      "        [-0.0611,  0.0069, -0.0310,  ..., -0.0078,  0.0290, -0.0572]]), hidden_states=None, attentions=None)\n",
      "**************************************************\n",
      "Perform pooling\n",
      "tensor([[ 0.0616, -0.2143, -0.0630,  ..., -0.0227,  0.0726, -0.0055],\n",
      "        [ 0.1287,  0.0034, -0.0479,  ..., -0.0673, -0.1962, -0.0270],\n",
      "        [ 0.1238, -0.0219, -0.0854,  ..., -0.0036,  0.0172,  0.0942]])\n",
      "**************************************************\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0225, -0.0783, -0.0230,  ..., -0.0083,  0.0265, -0.0020],\n",
      "        [ 0.0417,  0.0011, -0.0155,  ..., -0.0218, -0.0636, -0.0088],\n",
      "        [ 0.0416, -0.0073, -0.0287,  ..., -0.0012,  0.0058,  0.0316]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted', 'sentence is example that each word takes id']\n",
    "# sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "print(\"tokenizer output\")\n",
    "\n",
    "for i in encoded_input:\n",
    "    print(i)\n",
    "    print(encoded_input[i])\n",
    "print(50*\"*\")\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "print(\"Compute token embeddings\")\n",
    "print(model_output)\n",
    "print(50*\"*\")\n",
    "\n",
    "    \n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "\n",
    "print(\"Perform pooling\")\n",
    "print(sentence_embeddings)\n",
    "print(50*\"*\")\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154c6eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 2027, 2007, 2023, 2746, 6255,    2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7ae4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e0d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_hidden_state\n",
      "tensor([[[ 0.0966, -0.1707,  0.0076,  ...,  0.0234,  0.1014, -0.0425],\n",
      "         [ 0.0681, -0.1539, -0.1252,  ..., -0.0112,  0.0110, -0.0013],\n",
      "         [ 0.0151, -0.3782, -0.1018,  ..., -0.0874,  0.1020,  0.0773],\n",
      "         ...,\n",
      "         [ 0.1024, -0.3481, -0.0845,  ..., -0.1105,  0.0856, -0.0464],\n",
      "         [-0.0254,  0.0078, -0.0441,  ...,  0.0958, -0.0618, -0.0061],\n",
      "         [ 0.1180, -0.1216,  0.0249,  ..., -0.0096,  0.1404, -0.0325]]])\n",
      "pooler_output\n",
      "tensor([[ 8.7998e-02, -4.1801e-02,  1.8152e-02, -8.9510e-02, -3.9929e-02,\n",
      "         -3.1443e-02,  2.3688e-02,  3.0801e-02, -8.9669e-04, -8.9895e-02,\n",
      "          6.9226e-02, -1.6272e-03, -2.9426e-02,  4.3844e-02, -5.7402e-02,\n",
      "          4.1095e-02, -7.4796e-02,  1.7036e-02, -1.2585e-01,  5.3080e-02,\n",
      "         -8.2184e-02, -8.5882e-02, -5.2761e-02,  8.2555e-03,  1.0675e-01,\n",
      "         -6.7143e-02,  1.1777e-02, -3.0840e-02,  8.3433e-02,  7.9797e-02,\n",
      "         -4.2842e-02,  4.4696e-03,  5.0861e-02,  1.0116e-02, -3.6652e-02,\n",
      "          2.7334e-02,  8.3032e-02, -4.6489e-02, -5.9953e-02, -1.4984e-01,\n",
      "         -2.6236e-02,  4.6220e-02, -1.7039e-02,  6.4252e-02,  6.9301e-02,\n",
      "          5.3097e-02, -2.7547e-02,  2.0005e-01,  1.1476e-02,  2.7588e-02,\n",
      "         -7.1311e-02,  7.3668e-02,  1.5518e-02,  2.8209e-02,  2.2112e-02,\n",
      "         -1.9202e-02, -5.9576e-03, -1.0024e-02,  3.8895e-02, -1.0100e-01,\n",
      "         -2.8520e-02,  2.2267e-02, -1.7269e-02, -3.3599e-02, -5.7305e-02,\n",
      "         -2.8655e-02,  7.8889e-02, -3.5100e-03, -3.9085e-02, -3.1936e-02,\n",
      "         -9.8184e-02,  2.0548e-02,  1.3331e-01, -2.4831e-02,  6.1012e-02,\n",
      "          2.8324e-02, -4.8430e-02,  8.4832e-02, -4.4146e-03,  5.6428e-02,\n",
      "         -4.7041e-03, -7.4179e-02,  3.3760e-02, -1.1923e-02,  4.5725e-02,\n",
      "         -6.5110e-02, -6.2684e-02, -7.0724e-02, -5.2263e-02,  3.0882e-02,\n",
      "          6.3823e-02, -6.5689e-02,  1.9416e-02,  7.0468e-02, -1.4539e-01,\n",
      "          4.3555e-02,  6.6944e-02,  2.0413e-02, -1.0868e-01,  9.5057e-02,\n",
      "          9.5361e-02, -6.0902e-02, -9.4082e-02,  2.0980e-02,  5.9744e-03,\n",
      "         -3.3464e-02,  4.4193e-02,  2.3310e-02, -3.8738e-02, -1.4271e-01,\n",
      "         -3.4200e-02,  5.3085e-02,  2.0171e-02, -1.1191e-01,  1.0088e-02,\n",
      "         -6.2998e-02,  1.1991e-02, -2.1513e-02,  4.1760e-02, -1.2454e-01,\n",
      "         -7.4281e-02,  6.1157e-02,  2.8452e-02,  2.3175e-02, -4.5596e-02,\n",
      "          4.8296e-02, -2.3740e-02,  9.1009e-02, -9.5183e-02, -2.8304e-02,\n",
      "         -1.5809e-02, -3.4670e-02,  1.0397e-02,  2.1417e-02,  1.0211e-02,\n",
      "         -1.8524e-02,  1.3984e-02,  2.6403e-02,  7.7450e-02, -7.7067e-02,\n",
      "          2.6778e-02,  4.2332e-02,  1.0965e-01,  3.3156e-02, -3.4256e-02,\n",
      "         -1.6997e-02, -2.7976e-02,  4.0752e-02, -1.0385e-01,  4.0695e-02,\n",
      "          4.1519e-02, -4.7406e-02,  4.3517e-02, -6.9884e-02, -8.0332e-03,\n",
      "         -2.3331e-02, -9.6641e-02, -1.0612e-03,  2.4266e-02, -6.6999e-02,\n",
      "          1.2072e-01,  2.9134e-04, -1.4282e-02, -9.0323e-03, -5.1416e-03,\n",
      "         -7.8888e-03,  8.6623e-02,  2.1718e-02,  6.9098e-02, -1.2394e-01,\n",
      "         -1.0723e-02,  9.1677e-03,  4.8787e-03,  1.5285e-02, -2.1001e-03,\n",
      "          8.8347e-02, -2.6448e-02, -9.0431e-02,  2.1323e-02, -6.8781e-02,\n",
      "          3.1405e-02, -2.4385e-03,  2.5488e-02,  6.1410e-02,  1.7119e-02,\n",
      "         -2.9311e-02,  1.1102e-02, -1.0911e-02,  3.4617e-02,  3.7479e-02,\n",
      "          2.9252e-03, -3.3322e-02,  1.2180e-01, -6.6821e-03, -4.8263e-02,\n",
      "         -1.1139e-03,  1.2225e-01, -4.8766e-02, -1.1578e-02, -1.9797e-03,\n",
      "         -2.1853e-03, -4.0127e-03,  5.2274e-02, -8.1558e-02, -1.2915e-02,\n",
      "         -1.2413e-02, -5.7296e-02,  3.5231e-02, -1.9353e-02, -2.4100e-02,\n",
      "          1.8283e-02,  3.3551e-02, -2.3220e-02,  9.6836e-03,  5.8757e-02,\n",
      "         -2.3347e-02,  8.5392e-02, -3.1887e-02, -1.0356e-02, -4.2788e-02,\n",
      "          5.2672e-02,  2.8832e-02, -5.1762e-03,  4.8074e-02,  3.4438e-02,\n",
      "          5.1300e-02, -1.5601e-02, -1.3822e-02,  3.7809e-02,  4.5693e-02,\n",
      "         -1.1867e-02, -9.4487e-03,  3.0667e-03,  3.2217e-02,  1.8197e-02,\n",
      "         -6.4165e-02,  6.6198e-02,  7.1642e-02, -1.3842e-02,  8.0793e-03,\n",
      "          6.9550e-02,  2.3909e-02,  4.3979e-02,  4.1172e-03, -5.9479e-02,\n",
      "         -1.1178e-01,  4.5729e-02,  1.1930e-02, -8.2470e-02,  5.4631e-02,\n",
      "         -4.6946e-03, -3.9975e-03,  1.0135e-01,  8.8168e-03,  7.4977e-03,\n",
      "         -7.0473e-02, -8.1430e-02, -2.0216e-03,  9.2724e-03, -3.0318e-02,\n",
      "         -2.6239e-02,  6.3709e-02, -1.2929e-01, -3.2198e-02,  1.8035e-02,\n",
      "          2.2668e-02, -6.5570e-02, -1.4390e-02,  5.6850e-02,  5.8293e-02,\n",
      "          4.4765e-02, -5.4775e-02,  6.0690e-05,  6.1294e-02, -2.0638e-03,\n",
      "         -1.3812e-01, -1.9260e-02, -6.9606e-02, -3.7552e-02,  3.6569e-02,\n",
      "         -4.8025e-02, -2.2362e-02, -5.1139e-02,  5.6329e-03,  5.6993e-02,\n",
      "         -4.7741e-02,  5.2064e-02,  2.3915e-02,  1.3565e-02,  9.4834e-03,\n",
      "          1.1381e-01,  6.4375e-02, -4.7549e-02,  2.2993e-02,  1.0867e-01,\n",
      "         -1.9507e-02,  4.1435e-02, -9.2503e-03, -1.2307e-02,  3.7741e-03,\n",
      "          2.9436e-02, -4.5004e-02, -5.0117e-02, -2.7401e-02,  4.3730e-02,\n",
      "         -2.8730e-02, -2.5457e-02, -1.0449e-02, -2.7476e-02, -1.9215e-02,\n",
      "          2.3442e-02,  2.3186e-02,  7.4881e-02,  8.4808e-02,  9.3116e-02,\n",
      "         -2.6251e-02, -2.1611e-02,  7.7915e-02,  2.2861e-02,  5.5004e-02,\n",
      "         -8.8114e-02,  8.4500e-02, -1.8554e-02, -9.6159e-03, -3.2613e-02,\n",
      "         -2.1770e-02, -6.9179e-02, -6.5294e-02, -6.3237e-02,  4.1814e-02,\n",
      "          3.2960e-02,  5.0929e-02, -2.4690e-02, -3.7002e-02,  4.6843e-02,\n",
      "          4.0584e-03, -7.6746e-02, -3.1294e-02,  1.6748e-02,  2.2871e-02,\n",
      "          4.0805e-02, -4.5676e-02, -8.3102e-02, -8.3177e-02,  5.9886e-03,\n",
      "         -3.7506e-02, -1.3198e-01,  1.0821e-02,  3.8648e-02, -1.1429e-01,\n",
      "          4.2458e-02,  7.1170e-03, -4.9492e-02,  2.6627e-03, -3.6266e-02,\n",
      "          1.1731e-01, -1.1629e-01, -4.2129e-03, -5.2324e-02,  1.1744e-02,\n",
      "         -1.0610e-01,  4.1892e-02, -3.1115e-02, -3.7664e-02, -5.4792e-02,\n",
      "          3.2389e-02,  3.9621e-02,  2.4518e-02, -2.8163e-02,  3.6961e-02,\n",
      "          8.5336e-02,  5.7848e-02,  4.2100e-02, -1.6728e-02,  2.7213e-02,\n",
      "         -4.6749e-02, -2.8544e-02,  1.1666e-02,  8.0376e-02, -1.6722e-02,\n",
      "          3.9677e-02,  3.8355e-02,  8.6047e-02,  1.5983e-01, -3.4680e-02,\n",
      "          8.4283e-02,  6.2129e-02, -1.5180e-02, -8.6500e-02,  3.3710e-02,\n",
      "          3.5234e-02, -1.5752e-01,  5.4657e-02,  6.3519e-03,  4.3798e-04,\n",
      "         -3.9197e-02,  7.5543e-03,  5.3275e-02,  4.4834e-02,  5.1843e-02,\n",
      "         -4.6851e-02,  7.7701e-02, -3.5148e-03, -1.5763e-03, -1.4414e-02,\n",
      "         -3.1112e-02, -8.3161e-02, -1.2203e-01, -5.7022e-02, -1.0687e-01,\n",
      "         -4.5259e-02, -5.2406e-02, -2.1230e-02, -6.7184e-02, -4.0296e-02,\n",
      "          8.0949e-02,  4.8991e-02, -5.5584e-02,  8.5563e-02,  1.1411e-02,\n",
      "         -4.9785e-02, -7.4792e-02, -5.9815e-02, -5.3831e-02, -1.1802e-01,\n",
      "         -3.5187e-02,  2.9179e-02, -1.9222e-02,  4.6270e-02, -5.1997e-02,\n",
      "         -4.6692e-02, -2.4424e-02, -6.0125e-02, -1.1374e-03,  7.9416e-03,\n",
      "         -2.1773e-02,  2.8760e-02,  4.0780e-02, -1.9468e-02,  8.1278e-02,\n",
      "          1.1432e-02,  3.7234e-02, -8.5179e-02, -1.0785e-01, -1.9067e-02,\n",
      "          9.7183e-02,  6.2886e-02,  1.3061e-01,  5.0181e-02, -3.2167e-02,\n",
      "          6.5835e-03,  5.9585e-02,  3.2768e-02, -3.7931e-02,  1.1077e-02,\n",
      "          5.9922e-03,  1.9106e-04,  9.4843e-03,  4.5067e-02,  9.1717e-02,\n",
      "          1.3698e-02, -4.8181e-02,  1.1596e-01,  5.4874e-02, -5.3990e-02,\n",
      "          1.6710e-02,  3.3482e-02,  1.3450e-02, -9.2191e-04, -6.9536e-02,\n",
      "         -3.2561e-02, -2.1936e-03,  2.6172e-02,  4.5269e-03,  4.0982e-02,\n",
      "          7.8622e-03,  8.7666e-03,  2.8377e-02, -2.4291e-03, -3.8897e-02,\n",
      "          1.1506e-01, -7.2605e-02, -2.7263e-02, -3.9415e-02, -1.1168e-02,\n",
      "          3.2092e-02,  5.4109e-02,  4.1961e-03, -1.4374e-02,  2.9303e-02,\n",
      "         -3.0834e-02, -7.7972e-02, -8.4061e-02, -6.4169e-02,  3.2177e-02,\n",
      "         -1.5229e-02, -5.5456e-02, -1.0964e-01, -1.1855e-02, -1.8892e-02,\n",
      "         -3.1631e-02,  6.0135e-02,  5.2689e-03, -5.9648e-02,  6.8553e-02,\n",
      "          5.5197e-02, -5.3470e-02, -2.6396e-02, -4.2182e-02, -7.8434e-02,\n",
      "          1.0852e-01,  2.2624e-02,  6.7960e-02,  2.2169e-02,  1.0848e-01,\n",
      "         -8.3806e-03,  9.2845e-02,  5.7817e-03,  2.0439e-02,  3.9727e-02,\n",
      "         -1.1114e-02, -8.7127e-02, -4.0032e-02, -5.9718e-02, -6.6749e-02,\n",
      "          2.0366e-02,  8.7309e-04,  7.6547e-02, -4.0446e-03, -3.0763e-02,\n",
      "          7.6870e-02, -4.7949e-02,  6.0075e-02, -7.5903e-03, -1.1354e-01,\n",
      "         -9.8098e-02,  5.3064e-02, -9.3022e-02, -9.0185e-03,  6.4199e-02,\n",
      "          2.5712e-02,  4.0545e-02, -3.2990e-02,  6.1456e-02,  9.6893e-02,\n",
      "          3.1534e-02,  1.8401e-02, -4.8473e-03,  1.0222e-01, -1.9239e-02,\n",
      "          2.5746e-02, -5.7632e-02,  1.3614e-02, -3.9905e-02,  4.1531e-02,\n",
      "         -7.2951e-02,  3.7548e-02, -2.6318e-02,  1.5307e-01,  1.8278e-02,\n",
      "         -7.9320e-03,  1.1621e-02,  8.1870e-02,  3.5656e-02, -3.4161e-02,\n",
      "          7.7080e-02, -3.7486e-02,  2.2511e-02,  4.0862e-02, -7.6938e-02,\n",
      "          1.1470e-02, -1.4129e-02,  2.0180e-02,  6.4636e-02,  2.5681e-02,\n",
      "         -8.6426e-03,  3.4583e-03, -5.2428e-03,  4.6636e-02,  1.2238e-02,\n",
      "         -1.4254e-02, -4.3344e-02,  3.8103e-02,  8.3534e-02,  1.0730e-01,\n",
      "         -3.8944e-02,  3.1963e-02, -1.3678e-03,  1.8212e-02,  1.0879e-01,\n",
      "          1.3570e-02,  9.3868e-03, -3.7199e-02,  5.4118e-02, -1.2664e-02,\n",
      "          7.0594e-05, -2.5879e-02,  5.0110e-02, -5.0269e-02, -1.2979e-02,\n",
      "         -6.8675e-03,  6.9440e-02, -4.0012e-02,  2.6274e-02, -5.0911e-02,\n",
      "          3.4723e-02, -3.4827e-02,  1.2859e-02,  9.9510e-02, -5.0276e-03,\n",
      "          2.8490e-02, -4.5919e-02,  4.2762e-02, -3.0059e-03,  6.5076e-03,\n",
      "         -9.9296e-02, -7.9085e-03, -1.3076e-02,  3.2337e-02, -3.6824e-02,\n",
      "         -6.1366e-02, -2.4412e-02,  1.5649e-02,  1.4417e-02,  3.5906e-02,\n",
      "         -1.1079e-02, -5.0191e-02, -2.7508e-02,  4.4167e-02, -1.5884e-03,\n",
      "          6.4602e-03,  8.8995e-03,  7.0618e-02,  1.0181e-02, -8.5440e-02,\n",
      "         -7.1563e-02, -1.2393e-01,  5.8620e-02,  5.5108e-02,  1.5351e-02,\n",
      "          5.8314e-02,  3.9258e-02,  1.4962e-02, -4.4131e-02, -4.6189e-02,\n",
      "          1.0129e-01, -7.2181e-02, -1.7028e-04,  1.1714e-02, -6.6379e-03,\n",
      "         -3.8006e-02,  2.2774e-02, -1.1370e-01, -8.6575e-03, -5.0479e-02,\n",
      "         -1.1386e-02, -1.1102e-02, -3.5316e-02, -9.8511e-03,  2.4262e-02,\n",
      "         -1.1299e-02,  1.8797e-02,  9.2554e-03,  5.4906e-02,  1.7173e-02,\n",
      "         -3.1899e-02, -9.9228e-02,  1.1020e-01, -6.4058e-02,  2.3724e-02,\n",
      "         -4.0872e-02,  2.5279e-03,  7.6398e-02, -1.7323e-02,  7.1781e-02,\n",
      "          2.3301e-02, -9.5244e-02,  4.3141e-02,  1.3117e-01,  1.1222e-03,\n",
      "          5.6909e-02,  2.9812e-02,  5.4766e-03, -1.2029e-02,  6.4759e-02,\n",
      "          2.2714e-02, -2.5404e-02,  4.1693e-02,  2.4220e-02, -1.0060e-01,\n",
      "          3.0679e-02,  1.7106e-02,  2.3416e-02, -3.6627e-02,  2.7887e-02,\n",
      "         -6.9079e-02,  1.6841e-02, -2.5493e-02,  4.8324e-02, -7.9447e-02,\n",
      "          1.9981e-02,  5.9129e-02,  5.8085e-02, -1.6720e-02,  1.0948e-02,\n",
      "          1.1697e-01, -2.2043e-02, -6.0777e-02, -6.8540e-02, -3.3369e-02,\n",
      "         -3.9108e-03,  3.3556e-02,  8.0536e-02, -4.0084e-02,  1.0389e-02,\n",
      "         -2.4410e-02,  3.9139e-02, -1.3293e-02,  5.1745e-02, -3.0712e-03,\n",
      "          1.1016e-02,  1.4486e-01, -6.2939e-02,  3.0919e-02, -7.8087e-02,\n",
      "          9.3460e-03, -1.0368e-02, -1.7392e-03,  8.5121e-02,  2.5592e-02,\n",
      "          5.6631e-02, -6.7496e-02,  2.4309e-02,  3.5665e-02, -8.5403e-02,\n",
      "          6.6944e-02, -4.4056e-02,  9.8236e-02,  2.4255e-03,  3.3570e-02,\n",
      "          4.5001e-02,  4.1476e-02, -3.3689e-02,  1.5992e-02,  7.6330e-03,\n",
      "         -9.0148e-02, -2.8921e-02, -1.8689e-02,  5.1821e-02,  9.2724e-02,\n",
      "         -1.3061e-01,  7.1239e-02,  6.8346e-02,  1.0281e-01, -3.1798e-02,\n",
      "         -5.2952e-02,  2.6708e-02, -6.3409e-02, -2.8229e-03,  4.5812e-02,\n",
      "         -3.3618e-02,  1.6224e-03,  1.4784e-02,  6.7687e-02,  1.0614e-01,\n",
      "          8.6680e-02, -2.8368e-02, -3.8662e-02]])\n"
     ]
    }
   ],
   "source": [
    "for i in model_output:\n",
    "    print(i)\n",
    "    print(model_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd930e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((model_output[\"last_hidden_state\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a8b432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output[\"last_hidden_state\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ffb502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0966, -0.1707,  0.0076,  ...,  0.0234,  0.1014, -0.0425],\n",
       "         [ 0.0681, -0.1539, -0.1252,  ..., -0.0112,  0.0110, -0.0013],\n",
       "         [ 0.0151, -0.3782, -0.1018,  ..., -0.0874,  0.1020,  0.0773],\n",
       "         ...,\n",
       "         [ 0.1024, -0.3481, -0.0845,  ..., -0.1105,  0.0856, -0.0464],\n",
       "         [-0.0254,  0.0078, -0.0441,  ...,  0.0958, -0.0618, -0.0061],\n",
       "         [ 0.1180, -0.1216,  0.0249,  ..., -0.0096,  0.1404, -0.0325]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[\"last_hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d61b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output[\"pooler_output\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c5425e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0966, -0.1707,  0.0076,  ...,  0.0234,  0.1014, -0.0425],\n",
       "         [ 0.0681, -0.1539, -0.1252,  ..., -0.0112,  0.0110, -0.0013],\n",
       "         [ 0.0151, -0.3782, -0.1018,  ..., -0.0874,  0.1020,  0.0773],\n",
       "         ...,\n",
       "         [ 0.1024, -0.3481, -0.0845,  ..., -0.1105,  0.0856, -0.0464],\n",
       "         [-0.0254,  0.0078, -0.0441,  ...,  0.0958, -0.0618, -0.0061],\n",
       "         [ 0.1180, -0.1216,  0.0249,  ..., -0.0096,  0.1404, -0.0325]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b0776f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (762731624.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    *encoded_input\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "*encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0dd8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 2027, 2007, 2023, 2746, 6255,    2,    1,    1,    1],\n",
       "        [   0, 2173, 6255, 2007, 4995,    2,    1,    1,    1,    1],\n",
       "        [   0, 6255, 2007, 2746, 2012, 2173, 2777, 3142, 8913,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e40866e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2899493380.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in **encoded_input:\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in **encoded_input:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beeb5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IoT-Engine",
   "language": "python",
   "name": "iot-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

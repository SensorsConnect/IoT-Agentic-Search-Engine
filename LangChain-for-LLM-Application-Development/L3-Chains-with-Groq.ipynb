{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533b907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install -qU langchain-groq\n",
    "import os\n",
    "\n",
    "# Load a specific environment variable\n",
    "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b61a3-92eb-4891-90ee-1d10607b05ad",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4336d784-65c2-4a11-8489-b445b1fad177",
   "metadata": {
    "height": 250
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e92dff22",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain --upgrade\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "# from langchain import tool, LLMChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "943237a7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdcdb42d",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7abc20b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad44d1fb",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What a great question! Here are some suggestions for a company name that makes Queen Size Sheet Set:\\n\\n1. **Royal Bedding Co.**: This name plays off the idea of a Queen-sized bed being a luxurious and regal experience.\\n2. **Dreamweaver Sheets**: This name evokes a sense of comfort and coziness, and the word \"weaver\" suggests a high-quality, handmade product.\\n3. **Queenly Linens**: This name incorporates the idea of a Queen-sized bed and adds a touch of elegance with \"linens\".\\n4. **Slumber & Co.**: This name conveys a sense of relaxation and comfort, and the \"& Co.\" suggests a company that specializes in bedding.\\n5. **Soft & Serene**: This name emphasizes the softness and serenity of the sheets, which is a key selling point for a product like this.\\n6. **Bedding Bliss**: This name suggests that the sheets will bring joy and happiness to those who use them.\\n7. **Luxe Bedding Co.**: This name emphasizes the luxurious quality of the sheets and suggests a high-end product.\\n8. **Restful Nights**: This name conveys a sense of peaceful sleep and relaxation, which is exactly what people are looking for in a good night\\'s sleep.\\n9. **Cozy Corner Bedding**: This name incorporates a sense of warmth and comfort, and the \"corner\" suggests a cozy, intimate space.\\n10. **Sleep Sanctuary**: This name suggests a peaceful, restful space where people can escape and recharge.\\n\\nI hope one of these suggestions sparks some inspiration for your company name!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "# chain.run(product)\n",
    "chain.invoke({\"product\":\"Queen Size Sheet Set\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "febee243",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f31aa8a",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f5d5b76",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c1eb2c4",
   "metadata": {
    "height": 80,
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78458efe",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mWhat a great question!\n",
      "\n",
      "Naming a company can be a fun and creative process. Here are some suggestions for a company that makes Queen-size sheet sets:\n",
      "\n",
      "1. **Royal Linens**: This name plays off the idea of the Queen-size bed being a royal treatment, and \"Linens\" is a clear indication of what the company produces.\n",
      "2. **Queenly Bedding**: This name incorporates the idea of the Queen-size bed and emphasizes the high-quality bedding produced by the company.\n",
      "3. **ComfortCraft Co.**: This name highlights the company's focus on creating comfortable bedding products, and \"Co.\" suggests a company that crafts its products with care.\n",
      "4. **DreamWeave**: This name evokes the idea of a cozy, dreamy sleeping experience, and \"Weave\" references the manufacturing process of creating sheet sets.\n",
      "5. **Bedding Bliss**: This name conveys a sense of happiness and satisfaction, suggesting that the company's sheet sets will bring joy to those who sleep in them.\n",
      "6. **SlumberWorks**: This name plays off the idea of a \"workshop\" where craftsmen create high-quality bedding products, and \"Slumber\" emphasizes the importance of a good night's sleep.\n",
      "7. **SoftTouch Bedding**: This name highlights the tactile experience of sleeping on the company's soft, comfortable sheet sets.\n",
      "8. **Restful Nights**: This name emphasizes the importance of a good night's sleep and suggests that the company's sheet sets will help customers achieve just that.\n",
      "9. **Linen Luxe**: This name references the high-quality materials used in the company's sheet sets and suggests a luxurious sleeping experience.\n",
      "10. **Cozy Creations**: This name emphasizes the company's focus on creating soft, cozy bedding products that will make customers feel comfortable and relaxed.\n",
      "\n",
      "I hope one of these suggestions sparks some inspiration for your company's name!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHere is a 20-word description for the company:\n",
      "\n",
      "\"Royal Linens: Crafting luxurious Queen-size sheet sets with comfort, quality, and style, ensuring a restful night's sleep for all.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a 20-word description for the company:\\n\\n\"Royal Linens: Crafting luxurious Queen-size sheet sets with comfort, quality, and style, ensuring a restful night\\'s sleep for all.\"'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c129ef6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "016187ac",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb0730e",
   "metadata": {
    "height": 182,
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6accf92d",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7a46121",
   "metadata": {
    "height": 233,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89603117",
   "metadata": {
    "height": 165,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51b04f45",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'Hertz, fácil de encontrar con excelente servicio. Alquilamos un Auto DS (Citroen), este es un vehículo excepcional y es un placer conducirlo. El mejor sistema de navegación que he usado y perfecto. El precio era un poco alto pero valió la pena.\\nCliente feliz.',\n",
       " 'English_Review': 'Here is the translation:\\n\\n\"Hertz, easy to find with excellent service. We rented a Auto DS (Citroen), this is an exceptional vehicle and it\\'s a pleasure to drive it. The best navigation system I\\'ve ever used and perfect. The price was a bit high, but it was worth it.\\nHappy customer.\"\\n\\nLet me know if you have any other requests!',\n",
       " 'summary': 'Here is a summary of the review in 1 sentence:\\n\\nThe reviewer had a positive experience with Hertz, praising the ease of finding the location, excellent service, and exceptional vehicle (Citroen Auto DS) with a perfect navigation system, despite the slightly high price.',\n",
       " 'followup_message': '¡Claro! Aquí está un seguimiento de la respuesta en español:\\n\\nLa experiencia con Hertz fue absolutamente positiva, destacando la facilidad para encontrar la ubicación, el servicio excelente y el vehículo (Citroen Auto DS) con un sistema de navegación perfecto, a pesar del precio ligeramente alto.\\n\\nTranslation: Of course! Here is a follow-up response in Spanish:\\n\\nThe experience with Hertz was absolutely positive, highlighting the ease of finding the location, excellent service and the vehicle (Citroen Auto DS) with a perfect navigation system, despite the slightly high price.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"\"\"Hertz, fácil de encontrar con excelente servicio. Alquilamos un Auto DS (Citroen), este es un vehículo excepcional y es un placer conducirlo. El mejor sistema de navegación que he usado y perfecto. El precio era un poco alto pero valió la pena.\n",
    "Cliente feliz.\"\"\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ade83f4f",
   "metadata": {
    "height": 794,
    "tags": []
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f590e9f",
   "metadata": {
    "height": 403,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31b06fc8",
   "metadata": {
    "height": 80,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50bcc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eefec24",
   "metadata": {
    "height": 216,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('physics: Good for answering questions about physics\\n'\n",
      " 'math: Good for answering math questions\\n'\n",
      " 'History: Good for answering history questions\\n'\n",
      " 'computer science: Good for answering computer science questions')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "pprint(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f98018a",
   "metadata": {
    "height": 63,
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11b2e2ba",
   "metadata": {
    "height": 522,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1387109d",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fb7d560",
   "metadata": {
    "height": 97,
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d86b2131",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation in the context of thermodynamics?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation is a fundamental concept in thermodynamics, and it's a fascinating topic.\\n\\nIn simple terms, black body radiation refers to the emission of energy by an object in the form of electromagnetic radiation, such as light, when it is heated to a certain temperature. This radiation is emitted by the object itself, rather than being reflected or transmitted by it.\\n\\nIn the context of thermodynamics, black body radiation is important because it's a way for objects to release excess energy they've gained from being heated. When an object is heated, its molecules start moving faster and gaining kinetic energy. Some of this energy is converted into thermal energy, which is the energy associated with the motion of the molecules. However, as the object continues to heat up, it reaches a point where it can no longer absorb any more energy without emitting it as radiation. This is where black body radiation comes in.\\n\\nAt a given temperature, a black body will emit radiation across a wide range of frequencies, from low-frequency radio waves to high-frequency gamma rays. The peak frequency of this radiation depends on the temperature of the body. For example, a hot object like the surface of the sun will emit most of its radiation at shorter wavelengths, such as ultraviolet and X-rays, while a cooler object like a human body will emit most of its radiation at longer wavelengths, such as infrared.\\n\\nBlack body radiation is often described using Planck's law, which is a mathematical formula that relates the energy distribution of the radiation to the temperature of the object. This law was developed by Max Planck in the early 20th century and is a fundamental concept in quantum mechanics and thermodynamics.\\n\\nSo, to summarize, black body radiation is the emission of energy by an object in the form of electromagnetic radiation when it is heated to a certain temperature, and it's an important aspect of thermodynamics that helps us understand how objects interact with energy.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b717379",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A simple question, but one that requires a bit of finesse nonetheless!\\n\\nTo tackle this question, I\\'ll break it down into its component parts:\\n\\n1. What is the definition of the operation \"+\", also known as addition?\\n\\nIn mathematics, addition is defined as the operation of combining two or more numbers to produce a sum. In this case, we\\'re combining two numbers, 2 and 2.\\n\\n2. What are the properties of the numbers 2 and 2?\\n\\nBoth 2 and 2 are integers, which are a type of whole number. They are also equal in value, which means they have the same magnitude and opposite signs (since they\\'re both positive).\\n\\n3. How do we apply the definition of addition to these numbers?\\n\\nAccording to the definition, we combine the two numbers by adding their values together. In this case, we\\'re adding 2 + 2.\\n\\nNow, let\\'s calculate the sum:\\n\\n2 + 2 = ?\\n\\nTo do this, we can count the total number of units:\\n\\n2 units (from the first 2) + 2 units (from the second 2) = 4 units\\n\\nTherefore, the sum of 2 + 2 is equal to... (drumroll please)... 4!\\n\\nSo, the answer to the question \"what is 2 + 2\" is indeed 4.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29e5be01",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Why does every cell in our body contain DNA, specifically?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What a great question!\\n\\nThe answer lies in the fundamental concept of heredity and the mechanisms of biological inheritance. You see, DNA (Deoxyribonucleic acid) is the molecule that contains the genetic instructions used in the development and function of all living organisms. It\\'s often referred to as the \"blueprint\" or \"instructions\" for life.\\n\\nIn the case of cells, DNA serves as the primary repository of genetic information, which is crucial for the cell\\'s survival, growth, and reproduction. The DNA molecule is made up of two complementary strands that are twisted together to form a double helix structure. This structure is incredibly compact, allowing a vast amount of genetic information to be stored in a relatively small space.\\n\\nNow, every cell in our body contains DNA because it\\'s essential for the cell\\'s function. DNA provides the instructions for the cell to synthesize proteins, which are the building blocks of all biological structures and processes. It also contains information about the cell\\'s metabolism, response to environmental stimuli, and ability to adapt to changes.\\n\\nIn other words, DNA is the master blueprint for the cell\\'s activities, and without it, the cell would not be able to function properly. Think of DNA as the cell\\'s operating system, providing the instructions for all the cell\\'s processes to run smoothly.\\n\\nSo, to summarize, every cell in our body contains DNA because it\\'s necessary for the cell\\'s survival, growth, and reproduction. It\\'s the foundation of biological inheritance, allowing cells to pass on genetic traits to their offspring.\\n\\nWas that answer satisfactory?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f0121-cf7b-464d-bb3d-6357719188ed",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "912633a1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mainvoke(messages)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'messages' is not defined"
     ]
    }
   ],
   "source": [
    "await llm.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6378a95",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9456d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c46ddf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f97402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec128514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The function name, type hints, and docstring are all part of the tool\n",
    "# # schema that's passed to the model. Defining good, descriptive schemas\n",
    "# # is an extension of prompt engineering and is an important part of\n",
    "# # getting models to perform well.\n",
    "# def add(a: int, b: int) -> int:\n",
    "#     \"\"\"Add two integers.\n",
    "\n",
    "#     Args:\n",
    "#         a: First integer\n",
    "#         b: Second integer\n",
    "#     \"\"\"\n",
    "#     return a + b\n",
    "\n",
    "\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two integers.\n",
    "\n",
    "#     Args:\n",
    "#         a: First integer\n",
    "#         b: Second integer\n",
    "#     \"\"\"\n",
    "#     return a * b\n",
    "\n",
    "\n",
    "# def greating(query: str) -> str:\n",
    "#     \"\"\"Welcome the user prompt by discriping the serivce that you provide.\n",
    "\n",
    "#     Args:\n",
    "#         query: the user prompt\n",
    "#     \"\"\"\n",
    "#     return \"This Sensorconnect framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d7ee1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def greating(query: str) -> str:\n",
    "    \"\"\"Welcome the user prompt by discriping the serivce that you provide.\n",
    "\n",
    "    Args:\n",
    "        query: the user prompt\n",
    "    \"\"\"\n",
    "    return \"This Sensorconnect framework\"\n",
    "\n",
    "\n",
    "tools = [add, multiply,greating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e688c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [add, multiply, greating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9633e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# query = \"Hello\"\n",
    "query=\"what is 2 + 2\"\n",
    "AIMessage=llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82499916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_t74c', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1034, 'total_tokens': 1106, 'completion_time': 0.05798152, 'prompt_time': 0.379338634, 'queue_time': None, 'total_time': 0.437320154}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f9a41f4d-1f3c-4b73-a9ca-7faae56f4825-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'call_t74c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1034, 'output_tokens': 72, 'total_tokens': 1106})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24c05137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'greating', 'args': {'query': 'Hello'}, 'id': 'call_9vpf', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"Hello\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "287bf57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9vpf', 'function': {'arguments': '{\"query\":\"Hello\"}', 'name': 'greating'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1145, 'total_tokens': 1218, 'completion_time': 0.057639295, 'prompt_time': 0.173468779, 'queue_time': None, 'total_time': 0.231108074}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_873a560973', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ed033eb3-e2b5-4c49-a81b-c8cda9bcbec0-0', tool_calls=[{'name': 'greating', 'args': {'query': 'Hello'}, 'id': 'call_9vpf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1145, 'output_tokens': 73, 'total_tokens': 1218}),\n",
       " ToolMessage(content='This Sensorconnect framework', name='greating', tool_call_id='call_9vpf')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply, \"greating\":greating}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a68707d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_s3wr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_5hjy', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05df0543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s3wr', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_5hjy', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 1162, 'total_tokens': 1325, 'completion_time': 0.128667705, 'prompt_time': 0.175946418, 'queue_time': None, 'total_time': 0.304614123}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2245759c-5a61-49f7-8863-914904642a11-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_s3wr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_5hjy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1162, 'output_tokens': 163, 'total_tokens': 1325}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='call_s3wr'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='call_5hjy')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply, \"greating\":greating}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799ae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f964914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The English sentence \"I love programming\" can be translated to French as \"J\\'aime le programming\". However, it\\'s important to note that the French word for \"programming\" is \"programmation\", so a more accurate translation would be \"J\\'aime la programmation\".', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 28, 'total_tokens': 91, 'completion_time': 0.100014699, 'prompt_time': 0.002676149, 'queue_time': None, 'total_time': 0.102690848}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae11c19f-39fa-45c5-a0d6-35eba63cf261-0', usage_metadata={'input_tokens': 28, 'output_tokens': 63, 'total_tokens': 91})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef7ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The English sentence \"I love programming\" can be translated to French as \"J\\'aime le programming\". However, it\\'s important to note that the French word for \"programming\" is \"programmation\", so a more accurate translation would be \"J\\'aime la programmation\".', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 28, 'total_tokens': 91, 'completion_time': 0.10034904, 'prompt_time': 0.002800381, 'queue_time': None, 'total_time': 0.103149421}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-6e7f0a3f-d712-476c-b7ff-ab2f4168e4c7-0', usage_metadata={'input_tokens': 28, 'output_tokens': 63, 'total_tokens': 91})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c65177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GetPopulation',\n",
       "  'args': {'location': 'NY'},\n",
       "  'id': 'call_xj6s',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    '''Get the current weather in a given location'''\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "class GetPopulation(BaseModel):\n",
    "    '''Get the current population in a given location'''\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "model_with_tools = llm.bind_tools([GetWeather, GetPopulation])\n",
    "ai_msg = model_with_tools.invoke(\"What is the population of NY?\")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c82adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't cats play poker in the jungle?\", punchline='Too many cheetahs!', rating=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    '''Joke to tell user.'''\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "structured_model = llm.with_structured_output(Joke)\n",
    "structured_model.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6b2aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't cats play poker in the jungle?\", punchline='Too many cheetahs!', rating=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Joke(setup=\"Why don't cats play poker in the jungle?\",\n",
    "punchline='Too many cheetahs!', rating=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fb7001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 63,\n",
       "  'prompt_tokens': 28,\n",
       "  'total_tokens': 91,\n",
       "  'completion_time': 0.100190089,\n",
       "  'prompt_time': 0.002668933,\n",
       "  'queue_time': None,\n",
       "  'total_time': 0.102859022},\n",
       " 'model_name': 'mixtral-8x7b-32768',\n",
       " 'system_fingerprint': 'fp_c5f20b5bb1',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865e7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
